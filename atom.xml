<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Mr X's blog]]></title>
  <link href="http://xuyuandong.github.io/blog/atom.xml" rel="self"/>
  <link href="http://xuyuandong.github.io/blog/"/>
  <updated>2014-11-15T16:41:44+08:00</updated>
  <id>http://xuyuandong.github.io/blog/</id>
  <author>
    <name><![CDATA[XuYuandong]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[可扩展网站架构与分布式系统]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/"/>
    <updated>2014-11-10T17:27:12+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems</id>
    <content type="html"><![CDATA[<p><em>《Scalable Web Architecture and Distributed System》简译</em></p>

<p><strong>网站分布式系统设计原则</strong></p>

<p><em>可用性</em>
主要是容错和错误恢复。不能因为个别服务器宕机而影响用户访问。</p>

<p><em>高性能</em>
快速响应与低延迟。对关乎用户体验和广告收入的系统尤为重要。</p>

<p><em>可靠性</em>
读写一致性与持久性。当系统数据发生变化，请求应该返回最新的数据；当用户使用系统时，能够保证写入的数据在未来是不会丢失的。</p>

<p><em>扩展性</em>
为处理更大的流量或存储需求，而能够方便的增加服务器。</p>

<p><em>操控性</em>
易于管理、维护、修改或升级系统的功能。</p>

<p><em>低成本</em>
所有开发、运维、机器、人员、和培训的成本之和。</p>

<p><strong>基本知识</strong></p>

<p>设计系统架构时，有几点是一定要考虑的，如有哪些模块、他们如何组织起来、彼此间要做哪些trade off。这里举了一个例子来阐述这些核心的因素，包括服务、冗余、划分、错误处理等。</p>

<p><em>例：图片存取服务网站</em></p>

<p>想象要建设这样一个系统，用户可以上传图片到中心服务器，图片会通过web链接或者API（类似Flickr或Picasa）被请求。为了简单起见，我们把问题简化为两部分，上传图片和请求查看图片。我们希望上传速度要快，但我们常常更注重请求查看图片的响应效率，这一点可以被CDN服务所证明。</p>

<p>系统其他比较重要的方面包括：<br/>
1. 对系统存储图片的数量是无限制的，图片存储要由扩展能力。<br/>
2. 下载图片要有较低延迟。<br/>
3. 如果用户上传图片，图片需要被永久保存起来不会丢失，并随时可以被访问到。<br/>
4. 系统应该容易被管理和操作。<br/>
5. 系统应该有较低的成本，比较图片服务网站没有多少利润。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting1.jpg" title="Figure 1.1: Simplified architecture diagram for image hosting application" alt="Figure 1.1: Simplified architecture diagram for image hosting application" /></p>

<p><em>服务</em></p>

<p>首先，需要考虑将各个系统功能解耦合，每一部分定义自己的清晰的服务接口，这就是我们常说的Service-Oriented Architecture (SOA)，典型的做法是定义公共的抽象的API。在我们的问题中，主要是上传和获取图片这两部分服务的分离。</p>

<p>此外，我们可以发现图片写入的速度和时间其实会对图片读取效率有影响，因为两者要共享资源，所以这个影响是巨大的。即使上传和下载速度一样（这在大部分IP网络中是不可能的，一般下载和上传网速比约为3:1），读文件经常会读缓存，而写文件会写入磁盘（为保证最终一致性还可能多次），因此数据的写总是会更慢一些。(Pole Position, an open source tool for DB benchmarking, <a href="http://polepos.org/">http://polepos.org/</a> and results <a href="http://polepos.sourceforge.net/results/PolePositionClientServer.pdf.">http://polepos.sourceforge.net/results/PolePositionClientServer.pdf.</a>).</p>

<p>另一个架构设计问题是web服务器（Apach、lighttpd）对并发连接数的限制（default=500），在流量高峰时，写连接经常会耗尽这些资源（想象一下上传1M图片，持续时间超过一秒，不能异步返回的情况）。面对这种情况，最好就是将读写服务分离，这允许我们独立扩展这两部分，并方便对各自做效率优化、问题调试、以及扩展，参考Figure1.2。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting2.png" title="Figure 1.2: Splitting out reads and writes" alt="Figure 1.2: Splitting out reads and writes" /></p>

<p>举个例子，Flickr解决读写问题是通过将用户做水平划分（sharding），用户增加是可以向集群增加更多的shards (see the presentation on Flickr&rsquo;s scaling, <a href="http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html">http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html</a>)。产生的代价就是对系统的更新只能一个个shard进行（系统不在是一个整体），增加了运维的复杂度，谈及这个方面没有标准的解决方案，一切都要根据上一节的几项原则找到最佳的trade off。</p>

<p><em>冗余</em></p>

<p>为了有效应对系统宕机等错误，架构上必须对服务和数据做冗余处理。例如，文件需要存储多发，服务和应用也要部署多个备份或多个版本，避免单点故障。
服务冗余的另一个重要性在于创建了一个shared nothing系统，即是每个节点都可独立运转，整体上形成了去中心化，这对提高扩展性是很有帮助的。下图Figure 1.3表现了图片系统的冗余处理:</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting3.png" title="Figure 1.3: Image hosting application with redundancy" alt="Figure 1.3: Image hosting application with redundancy" /></p>

<p><em>划分</em></p>

<p>当数据量不能由单机进行存储，或某些操作需要大量计算资源时，增加存储或计算能力是必须的，这里有两种选择：垂直扩展或水平扩展。</p>

<p>垂直扩展还是扩充单机的性能，如增加磁盘、增加CPU和内存。水平扩展是指增加更多节点，如将数据做划分，每个节点只存储部分数据。</p>

<p>当使用水平扩展时，通用的技术是将服务做partitons/shards。划分准则是多样的，主要考虑划为不同的逻辑功能集合，比如将服务按地理边界划分。在我们的图片服务中，可以把图片存储在多个文件服务器中，每个服务器处理独一无二的图片集合，存储不够就加服务器。这样的设计需要一个命名策略把文件名和具体存储机器关联起来，比如一致性哈希策略，或者为每个图片赋予一个自增的ID，每个服务器关联一段区域范围的ID（有点像索引）。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting4.png" title="Figure 1.4: Image hosting application with redundancy and partitioning" alt="Figure 1.4: Image hosting application with redundancy and partitioning" /></p>

<p>分布式进行数据存储或运算是有挑战的，一个关键问题就是数据的局部性(locality)，操作离数据约近，效率越高，但分布式系统却强制通过网络来获取所需的数据。另一个问题是不一致性(inconsistency)，当不同服务同时读和写一个共享资源时，可能出现竞争条件。</p>

<p>划分数据的确会带来一定问题，但是它允许每个问题通过数据、负载、使用模式划整为零，变得易于扩展，但是如何处理引入的风险和错误这里没有详细讨论，可参考 <a href="http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/">http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/</a> 了解相关的容错和监控知识。</p>

<p><strong>建设高性能可扩展的数据访问服务的几个方面</strong></p>

<p><em>访问</em></p>

<p>大部分简单的网络服务都使用LAMP模型，如Figure 1.5</p>

<p><img src="http://www.aosabook.org/images/distsys/simpleWeb.png" title="Figure 1.5: Simple web applications" alt="Figure 1.5: Simple web applications" /></p>

<p>当网站做大时，有两个主要挑战：扩展App Server提高访问的能力，扩展Database Server的访问能力。假设我们有TB级数据，每个用户只会随机访问其中很小的一部分，类似于图片存取服务中的例子，如Figure 1.7.</p>

<p><img src="http://www.aosabook.org/images/distsys/accessingData.png" alt="Figure 1.7: Accessing specific data" /></p>

<p>TB级的数据不能够完全加载到内存中，这样就会读磁盘。而内存访问速度要比顺序读磁盘快6倍，比随机读磁盘快100,000倍，后面的文章会讨论如何解决这一问题。</p>

<p><em>缓存</em></p>

<p>缓存是一个拥有短期记忆的内存，他有一定的空间大小限制，访问速度快于直接去磁盘数据。缓存可以在系统架构任何层次上使用，但一般见于紧靠前端的位置。当某个节点需要查找数据时，先查自己携带的局部缓存，如果命中则直接返回。</p>

<p><img src="http://www.aosabook.org/images/distsys/multipleCaches.png" alt="Figure 1.9: Multiple caches" /></p>

<p>当有很多节点时呢？假设每个节点只拥有自己的局部缓存，如果负载均衡器是随机分发请求的，就会导致同一个请求发到不同的节点，之前节点的缓存数据就浪费了，降低了缓存命中率。有两种方法可以解决这个问题：全局缓存 和 分布式缓存。</p>

<p><em>全局缓存</em></p>

<p>全局缓存即所有节点都使用同一个缓存空间，一般是增加一台服务器专门做这件事。如果缓存没有命中，如何查询原始数据，有两种解决方式：一是由缓存自己来查找原始数据，另一种是由请求端查找原始数据，这两张架构如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/globalCache1.png" alt="Figure 1.10: Global cache where cache is responsible for retrieval" /></p>

<p><img src="http://www.aosabook.org/images/distsys/globalCache2.png" alt="Figure 1.11: Global cache where request nodes are responsible for retrieval" /></p>

<p>大部分网络服务都用第一种方式，缓存本身可以管理获取和驱逐数据，防止数据层请求泛滥。然而第二种实现方式在某些场景下也很有道理，比如当经常访问较大的文件时，缓存服务器会因空间紧张而导致较低的命中率，这样与后端数据的连接也会导致系统效率低下，不如把缓存服务器专门存储一些全局上较热门的数据效率来的更高。需要注意的是，第二种方式需要请求发起端要理解缓存的驱逐策略。</p>

<p><em>分布式缓存</em></p>

<p>分布式缓存是只每个节点管理一部分缓存数据，不同于局部缓存的是，整个缓存是通过一致性哈希策略划分的，这样一个请求节点是很快能知道该去哪里查它所需要的数据的。这种情况下，一个节点如果需要数据，会向另一个节点请求查缓存，未命中再去查原始数据。分布式缓存只需要通过增加请求池内的节点数即可扩展缓存空间。</p>

<p>分布式缓存当丢失节点时会存在降低命中率的缺陷，一些分布式缓存系统通过增加多份拷贝来解决这个问题，但随之会引来更多的复杂性问题，如增删节点情况下的多份缓存如何维护等，所以这个问题基本上就是不去理它，查不到缓存直接查原始数据来替代。</p>

<p><img src="http://www.aosabook.org/images/distsys/distributedCaching.png" title="Figure 1.12: Distributed cache" alt="Figure 1.12: Distributed cache" /></p>

<p>比较著名的开源缓存有Memcached (<a href="http://memcached.org/">http://memcached.org/</a>) ，既可以作为局部缓存，也可以作为分布式缓存。此外Facebook使用多种类型的缓存来提高网站效率 (<a href="http://sizzo.org/talks/">&ldquo;Facebook caching and performance&rdquo;</a>). Facebook也使用全局缓存(<a href="http://www.facebook.com/note.php?note_id=39391378919">&ldquo;Scaling memcached at Facebook&rdquo;</a>)。</p>

<p><em>代理</em></p>

<p>代理服务器是一种中间件软件或硬件，用于接收客户端请求，并传递给后端服务，一般用于过滤请求，记录请求，或者对请求做转换、包装和压缩。</p>

<p><img src="http://www.aosabook.org/images/distsys/proxies.png" alt="Figure 1.13 Proxy server" /></p>

<p>当多个节点的大量请求到来时，代理可以从系统层面优化请求流量，比如把相似请求汇集到一起。比如多个节点发送同一个请求索要数据（littleB）时，如果通过代理访问数据，则这些请求可以归为同一个，我们只需要读磁盘一次就能完成任务，不过这样设计的代价是为了把请求合并，每个响应都需要有较高的一些延迟。代理有点类似于缓存，但它不存储数据，它只优化请求，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/collapseRequests.png" alt="Figure 1.14: Using a proxy server to collapse requests" /></p>

<p>另一个用代理的方式是根据数据的存储地址接近性聚合请求，比如下图中会一次取出bigB用于响应三个请求。</p>

<p><img src="http://www.aosabook.org/images/distsys/collapseRequestsSpatial.png" alt="Figure 1.15: Using a proxy to collapse requests for data that is spatially close together" /></p>

<p>值得注意的是，你可以同时使用代理和缓存，但必须把缓存放在代理的前端，因为响应时间是根据最慢的一环来决定的，如果缓存放在代理后面，系统的平均响应时间至少是代理的响应时间，缓存的快速返回作用就无效了。</p>

<p>开源的代理系统很多，如<a href="http://www.squid-cache.org/">Squid</a>和<a href="https://www.varnish-cache.org/">Varnish</a>，把它们作为web服务器层的反向代理能够提高整体响应效率，降低大量处理客户端请求的工作。</p>

<p><em>索引</em></p>

<p>典型的就是倒排索引，可以对原始数据、数据库等建立，是一种增加存储空间和牺牲写入时间来换取快速查询的trade off。可以对同一份数据从不同角度建立索引，用于满足不同类型的数据过滤额查询。另外，可以通过嵌套索引（索引的索引），级联索引，粗粒度/细粒度的索引来降低对大量数据只建一个索引导致的索引数据过大问题。</p>

<p><em>负载均衡</em></p>

<p>负载均衡器可以允许多个请求端透明的访问多个具有相同功能的服务端，主要目的是为了处理高并发连接，并增加系统服务更多请求的扩展性，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/loadBalancer.png" alt="Figure 1.18: Load balancer" /></p>

<p>负载均衡的策略有很多，比如随机选择一个节点、round robin，或者根据节点的CPU/内存利用率等。在复杂的系统中，还会存在级联的负载均衡，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/multipleLoadBalancers.png" alt="Figure 1.19: Multiple load balancers" /></p>

<p>使用负载均衡的一个挑战是管理user-session相关数据，为了防止user-session被划分到不同服务器而造成session被割裂，不过目前这些问题基本都通过浏览器缓存、cookie和URL重写技术解决了。</p>

<p>负载均衡提供了准则函数用于测试系统中的节点是否健康，以便当某个节点不响应或者过载时将其从请求处理池中移除，利用系统中其他冗余节点进行服务。</p>

<p><em>队列</em></p>

<p>这里主要是探讨如何有效的管理写操作。当系统复杂时，数据常常需要写到不同服务器或索引的多个位置，因此是很耗时的，所以常常要通过队列将这些操作组织成异步处理的形式，提高效率。</p>

<p><img src="http://www.aosabook.org/images/distsys/synchronousRequest.png" alt="Figure 1.20: Synchronous request" /></p>

<p>同步的处理行为造成请求发生时，客户端必须等到服务端完成工作，这段时间不能进行其他工作；增加额外服务器不能解决这个问题，此外，如果服务端不可用或出错，上游客户端就会出错，客户端不能做到对错误处理透明化。</p>

<p><img src="http://www.aosabook.org/images/distsys/queues.png" alt="Figure 1.21: Using queues to manage requests" /></p>

<p>使用队列，可以让客户端递交写请求到队列后，服务端给一个应答句柄即返回，这样服务方式是异步的，客户端可以周期性检查任务状态，一旦完成再获取结果。同时，请求与应答结果在管理上是分离的，客户端在异步等待上一个结果完成前还可以去处理其他请求。</p>

<p>同时，队列对系统的错误处理提供了保护，例如可以创造一个鲁棒的队列用于重发响应失败的请求，这比把错误处理任务直接扔给客户端要好很多。</p>

<p>队列是在大型分布式系统下很基础的管理分布式通信的工具，相关的开源软件有<a href="http://www.rabbitmq.com/">RabbitMQ</a>，<a href="http://activemq.apache.org/">ActiveMQ</a>，<a href="http://kr.github.com/beanstalkd/">BeanstalkD</a>，偶尔也会使用<a href="http://zookeeper.apache.org/">Zookeeper</a>或者数据存储<a href="http://redis.io/">Redis</a>来完成</p>

<p><strong>原文来自：</strong>
<a href="http://www.aosabook.org/en/distsys.html">http://www.aosabook.org/en/distsys.html</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/">http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[矩阵分解在广告、推荐技术中的应用]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/"/>
    <updated>2014-11-06T12:23:15+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/">http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[程序化购买下的广告技术架构]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/"/>
    <updated>2014-11-02T12:21:01+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/02/architecture</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/">http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[流量分配与规划算法]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/"/>
    <updated>2014-10-19T12:23:35+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/10/19/allocation</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/'><a href="http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/">http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[预算平滑与在线分配策略]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/"/>
    <updated>2014-10-07T12:22:43+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/'><a href="http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/">http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用社交网络与行为定向建立用户模型]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/"/>
    <updated>2014-09-26T12:22:34+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/'><a href="http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/">http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于统计的CTR预估与实时计算]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/"/>
    <updated>2014-09-07T12:22:24+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/'><a href="http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/">http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高维度下的流量预估技术]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/"/>
    <updated>2014-08-16T12:20:26+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/16/forcast</id>
    <content type="html"><![CDATA[<p><strong>Holter-Winter Model</strong></p>

<p><strong>Data Sampling</strong></p>

<p><strong>High-Dimensional Search Index</strong></p>

<p><strong>Forcast with Constrains</strong></p>

<p><strong>Summery</strong></p>

<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/">http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅析RTB广告中的出价模型]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/"/>
    <updated>2014-08-05T12:24:02+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/">http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[广告在线投放中的排序与冷启动技术]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/"/>
    <updated>2014-08-02T12:21:21+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort</id>
    <content type="html"><![CDATA[<p>关于广告的在线投放技术，提及到策略和算法的东西可参考的并不像CTR预估那样多，原因主要还是和具体业务太相关，能够抽象出来的东西经过进一步简化，就比较少了；此外，由于学术圈比较难拿到真实数据，更难的是去做真实的大规模的实验，所以少了学术圈的推动，就难以热起来。但是，在工业界，线上策略对业务发展是非常重要的，并且会与工程、业务逻辑结合更加紧密，是公司里非常核心的技术。</p>

<p><strong>常见的扣费机制</strong></p>

<p>建立一个广告产品需要定义它的售卖对象、售卖方式和扣费机制（一种产品思维是把推荐也纳入到广告体系，甚至有人认为在移动互联网时代，可以把所有东西都认为是广告，即“产品即广告”；人们在消费信息，就是在消费广告，差异只在于这个信息是否有“buy”按钮，就是这条信息要不要触发扣费机制）。</p>

<p>首先，定义好售卖对象才能找到最匹配自己流量价值的广告主，定义好合适的售卖方式才能把广告主留住，帮广告主和自己找到共赢的合作方式。其中跟技术相关的就是扣费机制。按传统的几种方法来看，主要就是按CPM、CPC或者CPS来付费，对于常见的竞价广告系统来说，一般是在此基础上使用广义第二价格（GSP）计费。</p>

<p>刚接触广告的人一般看资料会误解为计费方式只有上面提到的几种，其实不是的，真正在商业领域会有各种各样不拘一格的广告扣费机制，核心目的是在提供流量资源（Supply）和产生的转化价值（Demand）之间找到双方认可的trade off；但是由于广告推广过程所涉及的多方（媒体、网络、广告主等）之间不能保证完全的信息透明，并且一旦涉及品牌效应和间接转化又无法量化衡量，所以才产生了或者偏向于Supply端、或者偏向于Demand端的扣费方式。</p>

<p>然后，我们在看一下竞价拍卖模式下的GSP扣费算法，排在第一位的成功竞拍者的扣费价格为出价第二高的价格加1个最小单位价格。对于广告来说呢？假设一个广告网络的竞价队列里同时存在以CPM/CPC/CPS扣费的广告，我们该如何排序？并如何计费呢？</p>

<p><strong>广告排序策略</strong></p>

<p>  <em>混合竞价</em></p>

<p>  上面提到一个很普遍存在的情况，即一个竞价队列中同时存在按CPM/CPC/CPS计费的广告，我们如何排序能够确保投放一个最优的广告呢？假设广告的出价都是广告主在预算了能够满足自己ROI前提下的价格，那么对于媒体或广告网络来说，从当前单次的曝光能够产生最大的收益的角度出发：<br/>
  CPM广告其收益为: Price{cpm} / 1000<br/>
  CPC广告其收益为: Price{cpc} * CTR <br/>
  CPS广告其收益为: Price{cps} * CTR * pCVR   <br/>
  我们将这三个可比拟的量统一称作eCPM，即effective CPM，其中CTR与pCVR是广告平台针对当前流量和当前投放的广告预估的点击率和点击后的转化率。</p>

<p>  <em>GSP计费一些讨论</em></p>

<p>  实际应用当中，不同的广告网络会对eCPM的计算有所变化，因为之前的公式是在流量资源被大量不同结算类型的广告主充分竞争情况下得出的结论，大家可以试想一下如果不满足这个条件，在GSP扣费原则下，会发生什么？对于天然CTR较低的广告位，会导致投CPC广告的客户居多，如果竞争不够充分，则出价高的广告主通过较低的GSP扣费就可以获得大量曝光；同理，对于天然CTR较高的广告位，投放CPM广告的客户可以利用较低的扣费赚取大量点击。</p>

<p>  此外，对于CPM广告，其决定排序的因素只有价格，所以广告主甚至可以出高价而不保证其广告创意对用户体验，这对媒体和广告网络的长期发展是极为不利的。因此，对不同计费类型的广告其eCPM计算可以略作修改的，一个常见的做法是：<br/>
$$
eCPM = Price * CTR^{\alpha} * pCVR^{\beta}
$$<br/>
其中，$ \alpha[cpm] = \alpha[cpc/cps] - 1, \beta[cpm/cpc] = \beta[cps] - 1 $ ，这里 $\alpha[cpc/cps]$ 和 $\beta[cps]$ 在默认条件下就是等于1的，可以通过微调 $\alpha, \beta$ 来控制CTR/CVR在不同类型计费广告中起的作用，从而让广告平台向用户体验好和对Demand端有利的广告有所倾斜。</p>

<p>  另外，对于GSP扣费，还有一个优美的统一公式，即：<br/>
$$
cost = Price * \frac{eCPM_2}{eCPM_1}
$$<br/>
无论何种类型的广告即排序顺序如何，都是可以套用的。这里还可以跟读者透露一个信息，即GSP只是绝大部分广告网络采样的扣费原则，目的是在按eCPM排序前提下，能够保证广告主自身无论如何调整出价，只要排名不变则其扣费就不会受到影响；这样，既能够保证广告网络的价格因素是稳定的，有利于把精力集中在受众定向的优化上，长期看还有利于广告网络整体竞争价格的上涨。</p>

<p><strong>冷启动问题</strong></p>

<p>按照上文的排序方案，一个直接的问题就是预估CTR或者CVR，但是无论是基于统计的方法还是基于模型的方法来预估CTR，前提是对候选广告有充分的投放样本可以参考。但是，实践中广告系统是高动态的，每日的新增广告比例还是很高的，这些没有投放记录的广告可以通过一些类似推荐中Content-based的方法估计出一个CTR分布，但是绝对不会很精确。因此，线上的投放策略一定要考虑到如何以最小的代价分配一些流量给新增广告，收集一些样本以便探索到新增广告的真实效果。</p>

<p>这方面在算法层面叫做“Explore &amp; Exploit”，即探索与开采，探索指浪费一部分流量投放非最优的新增广告进而收集其投放日志和分析它的投放效果，开采指在统计充分的广告中选择理论上最优的广告进行投放，两者之间是短期收入与长期利益的trade off。</p>

<p>这方面学术圈有大量的multi-arm bandit方面的论文从理论上讲如何做探索与开采，工业界比较好操作的策略大致我总结了以下三种：</p>

<p><strong>基于概率选择的E&amp;E策略</strong></p>

<p>长话短说，就是大家根据eCPM来排序，那么就根据eCPM来概率选择一个广告投放吧。优点是实现太简单了，能够做到大部分广告主都有消耗；缺点是毫无针对性，一是没有针对新增广告有目的的探索，二是没有针对短期收益做策略上的保障。</p>

<p><strong>基于置信度的E&amp;E策略</strong></p>

<p>一般是将广告按照曝光数量分为explore队列和exploit队列，然后设置一个explore比例，如果本次流量不需要做探索，则从exploit队列中选择最优广告进行投放；如果本次流量可以用来探索，则计算explore队列中每个广告的置信度，然后按置信度概率选择N个广告，再从N个广告中选择置信度最小（最需要探索的）进行投放。</p>

<p>这个策略来自雅虎的一篇论文《Exploitation and Exploration in a Performance based Contextual Advertising System》中被成为Confidence-based算法，其中置信度定义为 $tanh(frac{x}{b})$ ，x表示广告的曝光，b表示统计充分的阈值。</p>

<p>我认为该策略是有优点也存在未解决的问题的：优点在于策略的可控性，比如统计充分的阈值，探索的流量比例都是可调的；此外整个E&amp;E框架还可以进行扩展和修改，比如当前置信度概念只考虑了统计是否充分，如果不充分统计的广告其eCPM计算也有一定准确率，可以把eCPM等因素融入进去。这个策略的缺点在于，判断一个流量是否应该用于探索还是开采，纯粹是交给了随机数发生器，没有考虑当前的流量属性是否更适合探索还是开采，曝光是否充分的阈值也由经验决定，线上调参做实验成本高昂。</p>

<p><strong>基于Thompson采样的E&amp;E策略</strong></p>

<p>其实没有哪个E&amp;E框架能够在理论上证明是完美的，感觉这就是个实验科学话题，不过有的解决方案更偏工程化，有的解决方案会偏模型化。我认为Thompson采样策略是一个偏向于模型化的策略，它实际是个方法论，即CTR预估要估计出每个广告在当前流量下的CTR后验概率分布，然后按概率分布采样得到一个取值作为本次的预估CTR，整个排序和选择广告的过程是不需要有专门的探索或开采阶段的。</p>

<p>这看起来是个完美的解决方案，把任务直接交给CTR预估了。如果一个广告是统计充分的，那它的CTR后验概率分布形状应该非常尖锐（Sharp），统计期望CTR对应的概率密度应该非常大，这样采样的结果就大部分就是统计期望CTR；而如果一个广告是统计不充分的，那它的CTR后验概率分布形状将非常宽广（Wide），采样得到的结果会非常不集中，但随着样本积累越多，也会越来越接近统计平均。</p>

<p><em>Beta平滑</em></p>

<p>在使用统计方法做CTR预估的策略下，一般把统计似然的二项分布乘以先验beta分布做平滑，转化成后验beta分布 $B(a,b)$ ；所以，利用Thompson采样做CTR预估实际就是从beta分布中获得一个样本；当某个广告i被投放时，若有点击，则分布更新为 $B_i(a+1, b+1)$ ， 否则更新为 $B_i(a, b+1)$ ，下次采样则由更新后的分布决定；具体可以参考讲述统计平滑做CTR预估的博文。</p>

<p><em>LR模型</em></p>

<p>使用LR模型做CTR预估，CTR取值是由逻辑函数决定的，其统计不充分性来自于每个特征的学习样本是否充足；假设LR模型的损失函数使用L2正则化，则表示我们假设各维特征先验分布是高斯分布，学习模型时对每个特征权重的优化结果其实是特征的后验分布期望 $m_i$ ，我们还可以得到特征后验分布的标准差，如第i个特征 $q_i = \sum_j<sup>n</sup> x_{ij}^2 p_j (1 - p_j) $ ，其中 $p_j$ 是对样本j的CTR预测。</p>

<p>这样，整个Thompson采样过程其实就是对每个广告，取其每个特征i的分布 $N(m_i, q_i^{-1})$ ，对采样得到本次流量下该广告的特征采样值，进而计算该广告的CTR预估值。最终投放eCPM最大的，并按照投放结果是正样本还是负样本来更新每个特征的后验分布参数。</p>

<p>最后，需要补充的是，做好冷启动不能单纯看E&amp;E策略，还有更为重要的一环就是实时反馈，无论是统计还是模型，只有实时的把探索的效果反馈回系统，更正参数，才能引导系统向最优的方向运转，否则一切只是没有目标的低效率的探索而已。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/">http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[特征变换与离散化]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/"/>
    <updated>2014-07-23T12:23:52+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/">http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[点击率预估的机器学习模型及具体应用中的变种]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/"/>
    <updated>2014-07-16T12:21:57+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model</id>
    <content type="html"><![CDATA[<p><strong>位置偏置归一化</strong></p>

<p><strong>带偏移量的LR模型</strong></p>

<p><strong>混合逻辑回归模型</strong></p>

<p><strong>FTRL-Proximal .&amp;. L-BFGS</strong></p>

<p><strong>ADMM .&amp;. L-BFGS</strong></p>

<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/">http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于模型的CTR预估与ETL]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/"/>
    <updated>2014-07-08T12:21:44+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl</id>
    <content type="html"><![CDATA[<hr />

<p>在广告和推荐业务中，让人感觉最核心和高大上的一块就是CTR（点击率）预估。基于机器学习模型的CTR预估，说白了就是利用已有的投放数据（包括曝光和点击日志）学习出一组参数表示的函数，输入我们认为对CTR有影响的因素（特征），函数给出我们一个估计出的CTR结果，因此，基于模型的CTR预估主要工作时对特征的研究和对模型的研究。</p>

<p>由于广告、搜索的业务每家公司都不太一样，涉及到的场景会有所区别，因此对问题的建模也会有所不同，这不但衍生出了机器学习模型本身的变化（我们将再另一篇里专门讨论），更多的不同都体现在了对业务数据的处理，即是对特征的处理，尽可能把问题在特征层面规约到几个标准化的机器学习问题上。这篇文章将以CTR预估最常用的LR模型为例，主要讨论在大数据情况下具体实战时，该怎么建立整个数据处理、模型训练和效果预估流程，这些更多是ETL层面的问题。</p>

<ul>
<li><strong>LR模型</strong></li>
</ul>


<p>有人问我为什么CTR预估最常用LR模型，我想先思考一下这个问题的特点：<br/>
1. 训练标签是离散的0或1<br/>
2. 输出要求是[0~1]之间的概率<br/>
3. 其他原因，如线性模型学习效率上的优点等</p>

<p>对于点击或不点击这种事情，天然满足二项分布的似然损失函数：<br/>
$$
-log(F) = -\frac{1}{n} \sum_{i=1}^n \left[y_i \log(p_i) + (1 - y_i)\log(1 - p_i)\right]
$$</p>

<p>其中二项分布中的预测概率是逻辑函数<br/>
$$
Pr(y=1|x,w) = \frac{1}{1 + exp(-w^{T}x)}<br/>
$$
时，这就是逻辑回归（LR）模型了。通常为了防止过拟合，会在损失函数上加入正则项，L2正则项相当于给二项分布似然函数加上了高斯分布的先验，L1正则项相当于加入拉普拉斯先验。此外，需要指出的是逻辑回归中使用的特征一般要求是二值类别特征，即0/1特征。</p>

<ul>
<li><strong>准备数据</strong></li>
</ul>


<p>对于CTR预估来讲，根据数据动态变化情况不同，需要准备短至7天，长达1年的训练数据；数据是按天分区的，首先要分析一下数据中每日新增的广告或商品的比例，以及数据中新增率、天然点击率的周期性，这些对于选择时间窗口是非常有意义的。</p>

<p>假如我们有8天的训练数据，选择时间窗口为7天，我们则按照时间先后顺序，将数据划分为训练集（前7天），测试集（后1天），对于机器学习领域提到的验证集（主要是用来调超参数用的），可以用训练集数据再划分做交叉验证的方法，或者直接划出部分测试集。</p>

<p>在实战中，一旦建立起模型并应用于线上，验证集一般就不需要了，除非模型除了大偏差需要重调，否则既浪费时间模型又不稳定。测试集一般也是不存在的，因为上线时总是希望用全部最新的数据去训练。Google提出过一种progressive validation的方法，使用Online Learning时可以边训练边测试评估，评估结果能够在一定程度上表征模型的好坏，我们再另一篇专门讨论模型的文章中会再提到。</p>

<p>由于上线后模型每天都要跑，所以数据的收集和整理一定要是增量式的，流程上采用一个滚动时间窗口的机制，可以减少处理数据的时间，加速模型的更新速度，提高效果。如果广告或商品的新增速度过快，每日更新模型都不足以保证效果的实时性，就需要小时级更新的模型或者实时模型；对于小时级模型，建议与每日模型分别批量训练并在使用策略上做模型混合；对于实时模型，整个ETL流程都是在线增量计算的，工程实现上会有较大区别，但思想上是一致，所以本文主要是谈批量的ETL处理流程。</p>

<ul>
<li><strong>数据格式</strong></li>
</ul>


<p>一般大公司都会用Hadoop家族的开源工具来管理自己的数据仓库，因此建议使用hive来管理自己的曝光、点击日志，生成的训练数据格式可以包括：0/1标签信息，曝光环境，广告信息，用户信息等四类信息。其中，<br/>
曝光环境包括：流量来源、网络环境、页面上下文属性等；<br/>
广告信息包括：广告和创意、广告计划、广告主的ID和相关属性，越具体越好；<br/>
用户信息包括：人口属性、短期长期兴趣标签、和当前广告的互动频次等，越具体越好；</p>

<ul>
<li><strong>特征处理</strong></li>
</ul>


<p>首先，需要明确偏置特征因子，怎么明确呢？想象一下我们的CTR预估使用场景，当某个广告位上某个用户访问时，需要从一组广告中选择一个CTR最高的投放出去，在这个场景下，曝光上下文环境和用户都是确定的，只有广告可以变化，所以上下文和用户特征就是偏置因子，它们对候选集合来说是不变的，只决定CTR的整体大小水平，不决定相对区分力。</p>

<p>单独把偏置因素纳入到训练数据的特征集合是没有意义的，因为在使用时它们不能起到区别作用。解决这个问题有2种方法，一种是在模型建模时就把偏置因素考虑进去，这将形成对LR模型的一个变种；另一种办法是把偏置因素和广告进行交叉组合，形成联合特征，每个联合的特征才能表示当前广告在特征偏置条件下的一个特征；考虑上下文-用户-广告的三联合甚至更多维的联合，将导致特征数量迅速膨胀，但每种特征都是很细化的一种情况，统计不一定充分，整体日志量相比特征集合大小也得不充分了，每条样本包含的特征数量占据整体特征集合非常小的一部分，这就形成了CTR预估的高维稀疏的数据问题，因而给机器学习领域造成了一定的挑战。</p>

<p>做特征处理时，我一般会先对样本的交叉特征出现的正负样本数进行统计，每一类交叉特征中识别出有容易造成过拟合的问题特征，进行过滤掉部分问题样本。对于不充分统计的特征，可以考虑进行按特征联合的层次进行聚类，不充分的特征归约到一起，如果整层都不充分就归约到上一层，这样不但可以降低特征维度，也可以防止这类特征权重学习不充分导致的过拟合。此外，对于连续数值形特征，需要做离散区间化处理，归为2值特征，这样一能减少特征维度，二能更好描述非线性状态空间。关于特征变换和离散化是一个可以进一步挖掘的问题，我将在另外一篇博客中单独来讨论。</p>

<p>下面我们考虑用MapReduce实现这个过程：可以考虑在Map阶段完成从原始训练数据按照配置文件进行联合交叉特征的生成，然后发送给Reduce阶段；可以设置Partition方法按照特征类别进行分区，在Reduce阶段设置Grouping方法把需要层次聚类的一组特征划到同一个reduce阶段，进而完成特征的聚类、特征变换和离散化处理等过程。</p>

<ul>
<li><strong>多任务学习</strong></li>
</ul>


<p>实际业务中，广告和商品投放在不同的流量来源位置是很常见的，不同位置带来的流量可能有2种情况：一是人群分布相同或相似，二是人群分布差异很大；</p>

<p>对于第一种情况，流量对应的人群差异不大，位置主要影响了曝光的可见性，造成点击率整体上有偏置差异，但对CTR的相对分布影响不大。这种问题建议修改建模方式，如采用transfer learning，position normalization之类的策略，能够利用上全部训练数据做模型学习，取得的效果会更好。这部分我将在专门讨论模型的文章中说明。</p>

<p>对于第二种情况，就需要分别做处理，比如分位置做训练，把每个位置的CTR预估看成一个独立的问题解决。其实，也可以一起训练，但是要求所有特征都要和位置ID做联合，这样可以在优化时起到隔离作用；这样可以在一次优化过程中完成多任务学习。</p>

<p><em>结合VW的训练过程</em></p>

<p>VW是Vowpal Wabbit缩写，是工业界常用的一个开源机器学习工具，支持在Hadoop上对大规模数据使用AllReduce方式分布式训练机器学习模型。使用VW需要将训练样本转换成其要求的格式，更多的详情可以参考：<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">https://github.com/JohnLangford/vowpal_wabbit/wiki</a></p>

<p>首先，我们需要把特征进行编号（特征ID化），目的是在优化损失函数时，各个维度互不冲突。使用MapReduce的处理方式，可以对上一小节的联合特征处理结果在Map阶段按照资源位置进行分发，在Reduce阶段顺序编号。这样可以保证同一个资源位（同一个学习任务）内的特征ID互不冲突，使用资源位ID作为特征名字空间，能够保证即使所有位置一起优化，也不会彼此干扰。</p>

<p>然后，我们使用ID化之后的特征对原始训练数据进行编码，生成VW需要的格式;因为特征文件也是很大规模的数据，因此需要用MapReduce的多路输入方式，按资源位进行分发，在Reduce阶段进行特征ID与样本数据的关联和格式转换，形成可用的样本。</p>

<p>最后，直接使用VW提供的脚本即可完成模型的学习。</p>

<ul>
<li><strong>样本倾斜</strong></li>
</ul>


<p>众所周知，广告或推荐的点击数据相比曝光数量是非常小的，这样我们的训练样本中正样本的比例也是非常小的（常常 &lt; 1%），这种情况被成为样本倾斜。一些机器学习算法是对正负样本比例敏感的，好在我们使用的逻辑回归模型并不如此。不过从以下几个角度考虑，我们还是要讨论一下负样本采样的重要性：<br/>
1. 降低训练数据的规模，加速模型学习过程<br/>
2. 负样本中抽样能够使训练过程泛化能力更强，有助于减少测试集上的误差<br/>
对于第二点，我认为主要是解决了非常不充分的噪声特征，减少了模型过拟合的可能性，但是绝大部分情况下良好的模型选择和数据清洗过程才是保证泛化能力的关键，因此加速模型学习效率是考虑样本下采样的关键因素。</p>

<p>对负样本的下采样其实是模型训练效率与准确率之间的一种trade off，原理上其实是不会改变预估结果的，负样本抽样的原理如下：<br/>
$$
\frac{P(y=1|x)}{P(y=-1|x)} = \frac{P(x|y=1)P(y=1)}{P(x|y=-1)P(y=-1)} = \frac{P&#8217;(x|y=1)P&#8217;(y=1)}{P&#8217;(x|y=-1)P(y=-1)/r} = r \frac{P&#8217;(y=1|x)}{P&#8217;(y=-1|x)}
$$<br/>
上面等式成立的前提是负样本采样不改变类别的条件概率分布：$P(x|y)=P&#8217;(x|y)$ 。这样，进行采样后，我们的负对数损失函数会被降低 $log r$ ，有2种办法解决这个问题：<br/>
1. 训练完成模型后，在预测时将模型权重线性加和后，在加上 $log r$ 做补偿；
2. 训练过程中，对采样后保留下来的负样本提升 $1/r$ 权重，从而保证损失函数不变；<br/>
实践中，第一种处理方法的泛化能力比较好，方法二得到的模型在测试集上并不理想，可能的解释是对样本进行重要性加权的做法会破坏了原本的泛化错误边界。</p>

<ul>
<li><strong>评价指标</strong></li>
</ul>


<p>评价点击率预估效果有几种方式可以参考：<br/>
1. <em>auROC</em> 最常见的评价方式，能够解释是否点击率预估的越高，覆盖的真实点击数比例越大；auROC除了常见的计算曲线覆盖面积方式外，还有一种有意思的计算方法：随机从样本集中取一个正样本和一个负样本，统计正样本预估CTR比负样本预估CTR高的概率，这也一定程度上解释了它的物理意义。 <br/>
auROC的问题是换一个数据集，当正负样本比例变了，评价值就没有可比性了；因此指标只能用于静态数据集上不同方法的实验对比。值得注意的是，单纯谈论auROC的大小是没有意义的，不一样的数据集，一个AUC=0.9，一个AUC=0.7，不能说明前者算法就比后者好。<br/>
2. <em>logLoss</em> 直接带入损失函数计算结果，因为二项分布是对称的，所以评价值对正负样本比例不敏感，对损失函数按样本数量做平均后，可以用于横向对比。不过，我觉得预测值的方差范围是会对评估结果有影响的，但是预测值方差范围也是算法的一个评价方面，因此不能说这是该评价指标的缺点。<br/>
以上两种都是比较核心的评价指标，此外，还有一些辅助性的效果监控方法，用于探测模型其他方面的问题：<br/>
3. <em>calibration</em> 我们把样本按预估点击率排序，在数轴上对预估点击率划分等长区间，每个区间内落入的样本数可以统计正样本比例（即该区间内真是点击率），这两个点击率分别绘制在二维左边系横轴和纵轴上，理论上应该是满足y=x的一条直线。实际上，围绕着y=x的波动范围体现出预估的方差，偏离程度预示着偏差，还可以看出模型在点击率高位预估的好还是低位预估的好，这往往预示着模型对如missing feature等因素处理的效果等问题。<br/>
此外，对每类特征都进行calibration监测是一个好方法，能够更细致的发现模型内部的问题。</p>

<ul>
<li><strong>特征选择</strong></li>
</ul>


<p>提到特征选择，一般有2种理解：一是特征类别的选择，二是特征取值的选择。学术界有一部分研究专门通过模型优化来进行特征选择，如L1正则化来进行特征取值的选择，L1/L2 group lasso方法同时进行特征类别和取值的选择；不过这类把所有问题都交给优化算法，一是会导致人工控制的不够，二是计算复杂性也是大大增加了，此外能够处理大规模数据的开源项目和工具还不成熟。其实，工业界中花人力最多的特征工程还是通过实验方法挖掘哪些类特征该加入模型，以及如何融入到已存在的一大堆特征类别中，达到最优的组合。</p>

<p>假如我们有N种特征，直观的方法是做O(2<sup>N</sup>)种选择构造候选特征集合，然后训练这么多个模型，选择效果最好的，代价是时间成本。如果要把指数实验次数降下来，可以考虑用动态规划的方法把实验次数降至O(N<sup>2</sup>)，我们这里介绍用贪心策略将实验次数降至O(N).</p>

<p>让人耳熟能详的特征选择方法，如互信息等，能够评价特征与分类任务的相关性，但是没有考虑到如果已经存在了一批特征之后，如何再往特征集合里添加新特征。我们现在将问题建模如下，假设存在一批特征构成的LR模型，其logLoss为：<br/>
$$
\sum_{i=1}^n log(1 + exp(-y_i s_i))
$$</p>

<p>对于要加入的特征 $W = [w_1, &hellip;, w_d]$ ，第i个样本的预测值则为 $s_i + w_i$ ，需要优化的损失函数为：
$$
logLoss = \sum_{i=1}^n log(1 + exp(-y_i (s_i + w_i)))
$$</p>

<p>进一步分解为（各 $w_k$ 独立优化）：
$$
logLoss = \sum_k \sum_i log(1 + exp(-y_i (s_i + w_k)))
$$
这样问题转化为确定s条件下优化w以使logLoss最小的问题。</p>

<p>可以跟进一次牛顿迭代估计出近似w的解： $w_k = - \frac{L_k^&lsquo;(0)}{L_k^&ldquo;(0)}$<br/>
其中，
$$
L_k^{&rsquo;}(0) = \sum_i p_i - \frac{y_i + 1}{2}
$$
$$
L_k^{&lsquo;&rsquo;}(0) = \sum_i p_i (1 - p_i)
$$
$$
p_i = \frac{1}{1 + exp(-s_i)}
$$</p>

<p>一旦w计算完成，我们可以估计出加入w特征后logLoss的改进值，
$$
\Delta logLoss = \sum_k w_k L_k^{&lsquo;}(0) + 0.5 w_{k}^2 L_k^{&rsquo;&lsquo;}(0)
$$
这个改进值可以视为新特征相对已有特征集合下对学习任务的条件互信息。</p>

<p>因此特征选择的过程可以归纳为如下算法： <br/>
（1）选择从一个基本特征集合开始<br/>
（2）对已有特征训练一个模型<br/>
（3）对待选择的特征逐一计算条件互信息( $\Delta logLoss$ ）<br/>
（4）选择 $\Delta logLoss$ 最小的，把对应特征加入已有特征集合<br/>
（5）重复（2）步</p>

<ul>
<li><p><strong>一些可以讨论的问题</strong></p>

<p><em>反馈特征</em><br/>
一些业界公司（如m6d，weibo）会实时统计如广告主、广告计划等各个维度的点击率，以及上下文和广告直接交叉维度的点击率，这些实时反馈的特征作为模型训练的特征。对于使用这类特征业界实际是有争议的：一种考虑是反馈特征统计口径界定容易造成生成的条件概率意义相对模糊，形成的连续数值特征离散化处理对最终效果影响较大，尤其是取值范围高位和地位孤立点很多，不易做好离散化。<br/>
反馈特征的一个特点是一旦广告或推荐系统平稳后，反馈取值范围也是稳定的，这样可以一次性完成ETL和模型训练过程，之后模型的权重很长时间都不会变化，即使变化也可以通过较小的代价以原模型权重为初值训练完成。这种方式很适合训练过程非常耗时，不能频繁更新模型的情况。</p>

<p><em>CTR .vs. CVR</em><br/>
转化率预估是比点击率预估正样本量更小的学习任务，因此样本倾斜、数据稀疏等问题都更加严重了。因此，常常吧转化率预估问题转化为点击率预估和点击后的转化率预估（pCVR预估），以减轻一些数据问题带来的严重性。
此外，转化率对特征的考虑也是不一样的，诸如上下文环境等和媒体相关的特征对最终的转化价值都大大降低，但用户基本属性与广告或商品属性的相关性特征对转化率起到大大的作用，这是需要仔细挖掘和分析的。</p>

<p><em>模型后处理</em><br/>
这里涉及的主要是missing feature的问题，当新样本的特征不在学习好的模型特征集合中时，逻辑函数计算 $\sum wx$ 的线性加和中某些项就查不到权重，这样估计值就会出现极大的偏差。解决这种主要是对原有特征按照类别和联合层次建立一个针对missing feature的查找体系，从而解决线上新特征的权重赋值问题。</p></li>
</ul>


<p>最后，本博客涉及的特征处理、采样、模型后处理等策略涉及的具体实现，可以参考本人的github项目：<a href="https://github.com/xuyuandong/mapreduce_etl/tree/master">https://github.com/xuyuandong/mapreduce_etl/tree/master</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/">http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[从GitHub启程]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/"/>
    <updated>2014-07-05T14:51:57+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/05/post-title</id>
    <content type="html"><![CDATA[<hr />

<p>步入互联网行业早已超过三年，直到现在才开始建立自己的博客。在学校读书的时候虽然也有过几次写技术博客的日子，但都没有坚持下来，一是因为自己懒于把总结和整理的东西再编辑好发表出来，二是写着写着确实觉得才疏学浅，干货太少。工作之后，进度很快，也更忙碌了，一回首发现几年前接触的东西竟然快忘掉，电脑里只剩下一个个很难再去翻看的文件夹，于是发现，是时候该总结了。</p>

<p>回顾自己工作这几年，做过搜索、推荐、广告的系统架构和数据挖掘，但主要是在搜索、广告的一些关键技术和策略点上进行过深入的思考和开发，总结了一些面上的slides和点上code，这将在github这个平台上一一分享。特别感谢@Easy 让我有动力在github上开博客，而我电脑里这些沉积的资料也大部分是从工作过程中认识的内部的外部的同事朋友以及网络上感觉比较靠谱的分享中学习总结出来的，互联网的开放精神让这个行业飞快的进步，也让每个程序员都因此受益。</p>

<p>本篇我先粗描淡写讲一下如何用github打造个人blog，主要是援引网络上几个博客的内容。</p>

<ol>
<li><p>用github建立blog的原理  </br>
不错，用github写博客就像前端开发，这要从完整的博客系统角度理解。
博客系统需要一个类似CMS的博客站点管理部分，和一个后台的数据库，展示博客时系统会从数据库中获得内容动态形成HTML页面进行前端展示；然而，github和网上类似新浪博客的系统的区别是，他没有一个为博客定制的页面形成系统和数据库，但他是具有版本管理功能的代码仓库，所以我们只能通过把动态形成的页面变成静态页面，然后像代码一样提交给github，浏览博客是通过访问组织好的静态页面完成的。</p></li>
<li><p>配置ruby开发环境  </br>
<em>关键词：brew, ruby, rvm, rbenv, bundler</em><br/>
我个人不懂前端开发，所以也不太了解上面这些东西是什么，基本上就是照着网上一些文章照搬的，中间会发生不少错误，提示缺什么就装什么，基本能够搞定，我完成后看了一下自己的bash history，大致按照这么几条比较重要的命令：<br/>
[安装rvm]<br/>
<code>curl -sSL https://get.rvm.io | bash -s stable</code><br/>
[安装ruby]<br/>
<code>rvm install ruby-2.0.0-p594 &amp;&amp; rvm use 2.0.0</code><br/>
[安装brew]<br/>
<code>ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</code><br/>
<code>brew tab --repair</code><br/>
<code>brew update</code><br/>
[安装rbenv]<br/>
<code>brew install rbenv</code><br/>
<code>rbenv rehash</code><br/>
[按照bundler]<br/>
<code>gem update --system</code><br/>
<code>gem install bundler</code><br/>
<code>bundle install</code><br/>
到这里基本上装完了，不同系统由于曾经有过安装或者版本问题导致安装的过程都不会完全顺利，装成与否就看下一步octopress配置是否成功</p></li>
<li><p>配置和使用octopress  </br>
octopress是一个开发HTML静态页面网站的系统，在这个系统内我们只需要编辑MarkDown文件的内容就好了，页面风格主题之类的都交给octopress配置一下执行几个命令就能生成HTML静态页面网站，包括那些css，js文件等等，octopress可以和github关联起来，把静态页面网站提交给github，我们就可以通过github访问建好的博客站点了。<br/>
[注册个人github账号]<br/>
这一步就上github网站安装提示一步步来吧<br/>
[创建github上的blog项目]<br/>
按照这个链接来，有截图<a href="http://blog.csdn.net/renfufei/article/details/37725057  ">http://blog.csdn.net/renfufei/article/details/37725057  </a>
你会获得一个blog访问地址，比如：xxx.github.io/blog/<br/>
[下载并配置octopress]<br/>
<code>git clone git://github.com/imathis/octopress.git ~/dev/octopress</code> <br/>
<code>cd ~/dev/octopress</code>  <br/>
<code>rake install</code><br/>
<code>git remote add blog git@xxx.git</code> <br/>
[写第一篇blog]<br/>
<code>rake new_post["my first blog title"]</code><br/>
然后到~/dev/octopress/source/_posts/下找到对应的markdown文件编辑这篇博客<br/>
[生成静态网站]<br/>
<code>rake generate</code><br/>
[关联对应的git项目]<br/>
<code>rake setup_github_pages</code><br/>
[在4000端口预览]<br/>
<code>rake preview</code><br/>
[发布到github上]<br/>
<code>rake deploy</code></p></li>
</ol>


<p>到此大功告成，不过后面不断发布博客的过程中，还会遇到很多问题，比如git的版本管理问题，blog的格式问题，越多的问题就越要了解一些各方面的知识，比如git的使用，markdown语法，octopress的原理等等。</p>

<p>最后，希望本博客能够坚持写下去，发布更多搜索、推荐、广告、和数据挖掘相关内容！！！</p>

<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/'>http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/</a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'>http://xuyuandong.github.io/blog</a>
            </p>

]]></content>
  </entry>
  
</feed>
