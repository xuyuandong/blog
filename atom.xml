<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Mr X's blog]]></title>
  <link href="http://xuyuandong.github.io/blog/atom.xml" rel="self"/>
  <link href="http://xuyuandong.github.io/blog/"/>
  <updated>2014-12-04T18:40:06+08:00</updated>
  <id>http://xuyuandong.github.io/blog/</id>
  <author>
    <name><![CDATA[XuYuandong]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[广告数据管理平台漫谈]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/12/03/dmp-tutorial/"/>
    <updated>2014-12-03T18:55:34+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/12/03/dmp-tutorial</id>
    <content type="html"><![CDATA[<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/12/03/dmp-tutorial/'>http://xuyuandong.github.io/blog/blog/2014/12/03/dmp-tutorial/</a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'>http://xuyuandong.github.io/blog</a>
            </p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[可扩展网站架构与分布式系统]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/"/>
    <updated>2014-11-10T17:27:12+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems</id>
    <content type="html"><![CDATA[<p><em>《Scalable Web Architecture and Distributed System》简译</em></p>

<p><strong>网站分布式系统设计原则</strong></p>

<p><em>可用性</em>
主要是容错和错误恢复。不能因为个别服务器宕机而影响用户访问。</p>

<p><em>高性能</em>
快速响应与低延迟。对关乎用户体验和广告收入的系统尤为重要。</p>

<p><em>可靠性</em>
读写一致性与持久性。当系统数据发生变化，请求应该返回最新的数据；当用户使用系统时，能够保证写入的数据在未来是不会丢失的。</p>

<p><em>扩展性</em>
为处理更大的流量或存储需求，而能够方便的增加服务器。</p>

<p><em>操控性</em>
易于管理、维护、修改或升级系统的功能。</p>

<p><em>低成本</em>
所有开发、运维、机器、人员、和培训的成本之和。</p>

<p><strong>基本知识</strong></p>

<p>设计系统架构时，有几点是一定要考虑的，如有哪些模块、他们如何组织起来、彼此间要做哪些trade off。这里举了一个例子来阐述这些核心的因素，包括服务、冗余、划分、错误处理等。</p>

<p><em>例：图片存取服务网站</em></p>

<p>想象要建设这样一个系统，用户可以上传图片到中心服务器，图片会通过web链接或者API（类似Flickr或Picasa）被请求。为了简单起见，我们把问题简化为两部分，上传图片和请求查看图片。我们希望上传速度要快，但我们常常更注重请求查看图片的响应效率，这一点可以被CDN服务所证明。</p>

<p>系统其他比较重要的方面包括：<br/>
1. 对系统存储图片的数量是无限制的，图片存储要由扩展能力。<br/>
2. 下载图片要有较低延迟。<br/>
3. 如果用户上传图片，图片需要被永久保存起来不会丢失，并随时可以被访问到。<br/>
4. 系统应该容易被管理和操作。<br/>
5. 系统应该有较低的成本，比较图片服务网站没有多少利润。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting1.jpg" title="Figure 1.1: Simplified architecture diagram for image hosting application" alt="Figure 1.1: Simplified architecture diagram for image hosting application" /></p>

<p><em>服务</em></p>

<p>首先，需要考虑将各个系统功能解耦合，每一部分定义自己的清晰的服务接口，这就是我们常说的Service-Oriented Architecture (SOA)，典型的做法是定义公共的抽象的API。在我们的问题中，主要是上传和获取图片这两部分服务的分离。</p>

<p>此外，我们可以发现图片写入的速度和时间其实会对图片读取效率有影响，因为两者要共享资源，所以这个影响是巨大的。即使上传和下载速度一样（这在大部分IP网络中是不可能的，一般下载和上传网速比约为3:1），读文件经常会读缓存，而写文件会写入磁盘（为保证最终一致性还可能多次），因此数据的写总是会更慢一些。(Pole Position, an open source tool for DB benchmarking, <a href="http://polepos.org/">http://polepos.org/</a> and results <a href="http://polepos.sourceforge.net/results/PolePositionClientServer.pdf.">http://polepos.sourceforge.net/results/PolePositionClientServer.pdf.</a>).</p>

<p>另一个架构设计问题是web服务器（Apach、lighttpd）对并发连接数的限制（default=500），在流量高峰时，写连接经常会耗尽这些资源（想象一下上传1M图片，持续时间超过一秒，不能异步返回的情况）。面对这种情况，最好就是将读写服务分离，这允许我们独立扩展这两部分，并方便对各自做效率优化、问题调试、以及扩展，参考Figure1.2。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting2.png" title="Figure 1.2: Splitting out reads and writes" alt="Figure 1.2: Splitting out reads and writes" /></p>

<p>举个例子，Flickr解决读写问题是通过将用户做水平划分（sharding），用户增加是可以向集群增加更多的shards (see the presentation on Flickr&rsquo;s scaling, <a href="http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html">http://mysqldba.blogspot.com/2008/04/mysql-uc-2007-presentation-file.html</a>)。产生的代价就是对系统的更新只能一个个shard进行（系统不在是一个整体），增加了运维的复杂度，谈及这个方面没有标准的解决方案，一切都要根据上一节的几项原则找到最佳的trade off。</p>

<p><em>冗余</em></p>

<p>为了有效应对系统宕机等错误，架构上必须对服务和数据做冗余处理。例如，文件需要存储多发，服务和应用也要部署多个备份或多个版本，避免单点故障。
服务冗余的另一个重要性在于创建了一个shared nothing系统，即是每个节点都可独立运转，整体上形成了去中心化，这对提高扩展性是很有帮助的。下图Figure 1.3表现了图片系统的冗余处理:</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting3.png" title="Figure 1.3: Image hosting application with redundancy" alt="Figure 1.3: Image hosting application with redundancy" /></p>

<p><em>划分</em></p>

<p>当数据量不能由单机进行存储，或某些操作需要大量计算资源时，增加存储或计算能力是必须的，这里有两种选择：垂直扩展或水平扩展。</p>

<p>垂直扩展还是扩充单机的性能，如增加磁盘、增加CPU和内存。水平扩展是指增加更多节点，如将数据做划分，每个节点只存储部分数据。</p>

<p>当使用水平扩展时，通用的技术是将服务做partitons/shards。划分准则是多样的，主要考虑划为不同的逻辑功能集合，比如将服务按地理边界划分。在我们的图片服务中，可以把图片存储在多个文件服务器中，每个服务器处理独一无二的图片集合，存储不够就加服务器。这样的设计需要一个命名策略把文件名和具体存储机器关联起来，比如一致性哈希策略，或者为每个图片赋予一个自增的ID，每个服务器关联一段区域范围的ID（有点像索引）。</p>

<p><img src="http://www.aosabook.org/images/distsys/imageHosting4.png" title="Figure 1.4: Image hosting application with redundancy and partitioning" alt="Figure 1.4: Image hosting application with redundancy and partitioning" /></p>

<p>分布式进行数据存储或运算是有挑战的，一个关键问题就是数据的局部性(locality)，操作离数据约近，效率越高，但分布式系统却强制通过网络来获取所需的数据。另一个问题是不一致性(inconsistency)，当不同服务同时读和写一个共享资源时，可能出现竞争条件。</p>

<p>划分数据的确会带来一定问题，但是它允许每个问题通过数据、负载、使用模式划整为零，变得易于扩展，但是如何处理引入的风险和错误这里没有详细讨论，可参考 <a href="http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/">http://katemats.com/2011/11/13/distributed-systems-basics-handling-failure-fault-tolerance-and-monitoring/</a> 了解相关的容错和监控知识。</p>

<p><strong>建设高性能可扩展的数据访问服务的几个方面</strong></p>

<p><em>访问</em></p>

<p>大部分简单的网络服务都使用LAMP模型，如Figure 1.5</p>

<p><img src="http://www.aosabook.org/images/distsys/simpleWeb.png" title="Figure 1.5: Simple web applications" alt="Figure 1.5: Simple web applications" /></p>

<p>当网站做大时，有两个主要挑战：扩展App Server提高访问的能力，扩展Database Server的访问能力。假设我们有TB级数据，每个用户只会随机访问其中很小的一部分，类似于图片存取服务中的例子，如Figure 1.7.</p>

<p><img src="http://www.aosabook.org/images/distsys/accessingData.png" alt="Figure 1.7: Accessing specific data" /></p>

<p>TB级的数据不能够完全加载到内存中，这样就会读磁盘。而内存访问速度要比顺序读磁盘快6倍，比随机读磁盘快100,000倍，后面的文章会讨论如何解决这一问题。</p>

<p><em>缓存</em></p>

<p>缓存是一个拥有短期记忆的内存，他有一定的空间大小限制，访问速度快于直接去磁盘数据。缓存可以在系统架构任何层次上使用，但一般见于紧靠前端的位置。当某个节点需要查找数据时，先查自己携带的局部缓存，如果命中则直接返回。</p>

<p><img src="http://www.aosabook.org/images/distsys/multipleCaches.png" alt="Figure 1.9: Multiple caches" /></p>

<p>当有很多节点时呢？假设每个节点只拥有自己的局部缓存，如果负载均衡器是随机分发请求的，就会导致同一个请求发到不同的节点，之前节点的缓存数据就浪费了，降低了缓存命中率。有两种方法可以解决这个问题：全局缓存 和 分布式缓存。</p>

<p><em>全局缓存</em></p>

<p>全局缓存即所有节点都使用同一个缓存空间，一般是增加一台服务器专门做这件事。如果缓存没有命中，如何查询原始数据，有两种解决方式：一是由缓存自己来查找原始数据，另一种是由请求端查找原始数据，这两张架构如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/globalCache1.png" alt="Figure 1.10: Global cache where cache is responsible for retrieval" /></p>

<p><img src="http://www.aosabook.org/images/distsys/globalCache2.png" alt="Figure 1.11: Global cache where request nodes are responsible for retrieval" /></p>

<p>大部分网络服务都用第一种方式，缓存本身可以管理获取和驱逐数据，防止数据层请求泛滥。然而第二种实现方式在某些场景下也很有道理，比如当经常访问较大的文件时，缓存服务器会因空间紧张而导致较低的命中率，这样与后端数据的连接也会导致系统效率低下，不如把缓存服务器专门存储一些全局上较热门的数据效率来的更高。需要注意的是，第二种方式需要请求发起端要理解缓存的驱逐策略。</p>

<p><em>分布式缓存</em></p>

<p>分布式缓存是只每个节点管理一部分缓存数据，不同于局部缓存的是，整个缓存是通过一致性哈希策略划分的，这样一个请求节点是很快能知道该去哪里查它所需要的数据的。这种情况下，一个节点如果需要数据，会向另一个节点请求查缓存，未命中再去查原始数据。分布式缓存只需要通过增加请求池内的节点数即可扩展缓存空间。</p>

<p>分布式缓存当丢失节点时会存在降低命中率的缺陷，一些分布式缓存系统通过增加多份拷贝来解决这个问题，但随之会引来更多的复杂性问题，如增删节点情况下的多份缓存如何维护等，所以这个问题基本上就是不去理它，查不到缓存直接查原始数据来替代。</p>

<p><img src="http://www.aosabook.org/images/distsys/distributedCaching.png" title="Figure 1.12: Distributed cache" alt="Figure 1.12: Distributed cache" /></p>

<p>比较著名的开源缓存有Memcached (<a href="http://memcached.org/">http://memcached.org/</a>) ，既可以作为局部缓存，也可以作为分布式缓存。此外Facebook使用多种类型的缓存来提高网站效率 (<a href="http://sizzo.org/talks/">&ldquo;Facebook caching and performance&rdquo;</a>). Facebook也使用全局缓存(<a href="http://www.facebook.com/note.php?note_id=39391378919">&ldquo;Scaling memcached at Facebook&rdquo;</a>)。</p>

<p><em>代理</em></p>

<p>代理服务器是一种中间件软件或硬件，用于接收客户端请求，并传递给后端服务，一般用于过滤请求，记录请求，或者对请求做转换、包装和压缩。</p>

<p><img src="http://www.aosabook.org/images/distsys/proxies.png" alt="Figure 1.13 Proxy server" /></p>

<p>当多个节点的大量请求到来时，代理可以从系统层面优化请求流量，比如把相似请求汇集到一起。比如多个节点发送同一个请求索要数据（littleB）时，如果通过代理访问数据，则这些请求可以归为同一个，我们只需要读磁盘一次就能完成任务，不过这样设计的代价是为了把请求合并，每个响应都需要有较高的一些延迟。代理有点类似于缓存，但它不存储数据，它只优化请求，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/collapseRequests.png" alt="Figure 1.14: Using a proxy server to collapse requests" /></p>

<p>另一个用代理的方式是根据数据的存储地址接近性聚合请求，比如下图中会一次取出bigB用于响应三个请求。</p>

<p><img src="http://www.aosabook.org/images/distsys/collapseRequestsSpatial.png" alt="Figure 1.15: Using a proxy to collapse requests for data that is spatially close together" /></p>

<p>值得注意的是，你可以同时使用代理和缓存，但必须把缓存放在代理的前端，因为响应时间是根据最慢的一环来决定的，如果缓存放在代理后面，系统的平均响应时间至少是代理的响应时间，缓存的快速返回作用就无效了。</p>

<p>开源的代理系统很多，如<a href="http://www.squid-cache.org/">Squid</a>和<a href="https://www.varnish-cache.org/">Varnish</a>，把它们作为web服务器层的反向代理能够提高整体响应效率，降低大量处理客户端请求的工作。</p>

<p><em>索引</em></p>

<p>典型的就是倒排索引，可以对原始数据、数据库等建立，是一种增加存储空间和牺牲写入时间来换取快速查询的trade off。可以对同一份数据从不同角度建立索引，用于满足不同类型的数据过滤额查询。另外，可以通过嵌套索引（索引的索引），级联索引，粗粒度/细粒度的索引来降低对大量数据只建一个索引导致的索引数据过大问题。</p>

<p><em>负载均衡</em></p>

<p>负载均衡器可以允许多个请求端透明的访问多个具有相同功能的服务端，主要目的是为了处理高并发连接，并增加系统服务更多请求的扩展性，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/loadBalancer.png" alt="Figure 1.18: Load balancer" /></p>

<p>负载均衡的策略有很多，比如随机选择一个节点、round robin，或者根据节点的CPU/内存利用率等。在复杂的系统中，还会存在级联的负载均衡，如下图：</p>

<p><img src="http://www.aosabook.org/images/distsys/multipleLoadBalancers.png" alt="Figure 1.19: Multiple load balancers" /></p>

<p>使用负载均衡的一个挑战是管理user-session相关数据，为了防止user-session被划分到不同服务器而造成session被割裂，不过目前这些问题基本都通过浏览器缓存、cookie和URL重写技术解决了。</p>

<p>负载均衡提供了准则函数用于测试系统中的节点是否健康，以便当某个节点不响应或者过载时将其从请求处理池中移除，利用系统中其他冗余节点进行服务。</p>

<p><em>队列</em></p>

<p>这里主要是探讨如何有效的管理写操作。当系统复杂时，数据常常需要写到不同服务器或索引的多个位置，因此是很耗时的，所以常常要通过队列将这些操作组织成异步处理的形式，提高效率。</p>

<p><img src="http://www.aosabook.org/images/distsys/synchronousRequest.png" alt="Figure 1.20: Synchronous request" /></p>

<p>同步的处理行为造成请求发生时，客户端必须等到服务端完成工作，这段时间不能进行其他工作；增加额外服务器不能解决这个问题，此外，如果服务端不可用或出错，上游客户端就会出错，客户端不能做到对错误处理透明化。</p>

<p><img src="http://www.aosabook.org/images/distsys/queues.png" alt="Figure 1.21: Using queues to manage requests" /></p>

<p>使用队列，可以让客户端递交写请求到队列后，服务端给一个应答句柄即返回，这样服务方式是异步的，客户端可以周期性检查任务状态，一旦完成再获取结果。同时，请求与应答结果在管理上是分离的，客户端在异步等待上一个结果完成前还可以去处理其他请求。</p>

<p>同时，队列对系统的错误处理提供了保护，例如可以创造一个鲁棒的队列用于重发响应失败的请求，这比把错误处理任务直接扔给客户端要好很多。</p>

<p>队列是在大型分布式系统下很基础的管理分布式通信的工具，相关的开源软件有<a href="http://www.rabbitmq.com/">RabbitMQ</a>，<a href="http://activemq.apache.org/">ActiveMQ</a>，<a href="http://kr.github.com/beanstalkd/">BeanstalkD</a>，偶尔也会使用<a href="http://zookeeper.apache.org/">Zookeeper</a>或者数据存储<a href="http://redis.io/">Redis</a>来完成</p>

<p><strong>原文来自：</strong>
<a href="http://www.aosabook.org/en/distsys.html">http://www.aosabook.org/en/distsys.html</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/">http://xuyuandong.github.io/blog/blog/2014/11/10/scalable-web-systems/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[矩阵分解在广告、推荐技术中的应用]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/"/>
    <updated>2014-11-06T12:23:15+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/">http://xuyuandong.github.io/blog/blog/2014/11/06/matrix-factorization/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[程序化购买下的广告技术架构]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/"/>
    <updated>2014-11-02T12:21:01+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/11/02/architecture</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/'><a href="http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/">http://xuyuandong.github.io/blog/blog/2014/11/02/architecture/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[流量分配与规划算法]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/"/>
    <updated>2014-10-19T12:23:35+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/10/19/allocation</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/'><a href="http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/">http://xuyuandong.github.io/blog/blog/2014/10/19/allocation/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[预算平滑与在线分配策略]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/"/>
    <updated>2014-10-07T12:22:43+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/'><a href="http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/">http://xuyuandong.github.io/blog/blog/2014/10/07/budget-smooth/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[利用社交网络与行为定向建立用户模型]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/"/>
    <updated>2014-09-26T12:22:34+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/'><a href="http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/">http://xuyuandong.github.io/blog/blog/2014/09/26/user-profile/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于统计的CTR预估与实时计算]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/"/>
    <updated>2014-09-07T12:22:24+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/'><a href="http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/">http://xuyuandong.github.io/blog/blog/2014/09/07/statistics-ctr/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高维度下的流量预估技术]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/"/>
    <updated>2014-08-16T12:20:26+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/16/forcast</id>
    <content type="html"><![CDATA[<p><strong>Holter-Winter Model</strong></p>

<p><strong>Data Sampling</strong></p>

<p><strong>High-Dimensional Search Index</strong></p>

<p><strong>Forcast with Constrains</strong></p>

<p><strong>Summery</strong></p>

<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/">http://xuyuandong.github.io/blog/blog/2014/08/16/forcast/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浅析RTB广告中的出价模型]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/"/>
    <updated>2014-08-05T12:24:02+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model</id>
    <content type="html"><![CDATA[<p>随着RTB广告模式越来越火热，DSP技术也开始被作为各广告网络公司的核心技术来重点研发；其中，我认为一个DSP在技术上与传统广告系统最明显的差别就是增加了一个实时出价模型。关于出价模型的比较可操作的学术论文比较少，一是因为技术比较新，二是因为确实是公司最最核心的技术，不会轻易披露。我在这里会根据已知的业界两家公司的出价技术，结合自己的认识和实践，总结性的介绍一下开发一个出价模型所涉及的技术路线和操作方法论。</p>

<p><strong>制定模型目标</strong></p>

<p>任何出价模型都是以盈利为目的的，可以以广告主的ROI为目标，或者以DSP平台收益最大化为目标；作为广告平台，从赚钱的角度，我们以收益最大化为目标：</p>

<p>$f = max \sum (cost_i - bid_i) * winningrate_i$</p>

<p>有意思的是，这里winning_rate又是bid的正相关函数。这里cost可以认为是eCPM，如果从广告主ROI角度考虑可以认为是获得一个转化的收益，bid则是DSP对AdExchange的报价，即我们的出价，可以认为是获得一个转化的成本；</p>

<p>另外可以看到如下规律，出价bid越高，净收益越小，但胜出率越大；反之，出价bid越小，净收益越大，但胜出的概率却小了；因此，对一次竞价而言，存在一个最佳的出价，在净收益和胜出率中取得最佳平衡点，获取最大的有效真实收益。</p>

<p>这里没有提到的是，目标函数是有预算约束的，最优化过程中要在约束问题范围内求解，不过为了简化处理，我们暂时先忽略这一约束的存在。</p>

<p><strong>计算胜出率</strong></p>

<p>从上面的目标函数可以看出，对于特定上下文环境下的一次广告曝光竞拍机会，能够确定其胜出率对出价的关系函数是很重要的。胜出率和CTR一样受到多种因素的影响，最主要的影响因子可以认为是用户年龄、性别、兴趣等属性，以及广告位等流量来源和上下文属性。</p>

<p>我们可以把胜出率表示为p(winning_rate | bid, user, context)，而在计算最优出价时，最好是能够把user、context变量积分掉。不过在一般情况下是很难计算出这样一个winning_rate对bid的泛函关系的，工业界常用的方法是从历史竞价日志中挖掘出一个叫做bid landscape的数据查询模型，详细可以参考Yahoo的论文《Bid Landscape Forecasting in Online Ad Exchange Marketplace》。</p>

<p>从直观上理解，bid landscape就是一颗根据历史竞价日志中影响竞价的条件、出价、以及是否胜出建立的树形索引；其中，影响竞价的条件，如用户和上下文属性，构成了树枝节点，对于特定一条路径到达的叶子节点，其对应着该路径代表的竞价条件下bid与winning_rate的函数关系，一般用高斯分布来描述这个关系；所以，一条树枝和其叶子节点就管理着一个高斯分布，利用这个分布可以计算bid的大小对应着winning的概率。上述的论文还提到一个有价值的观点，即对于不充分统计的树枝可以合并成一个*节点，用于查询索引时做模糊匹配，可以解决数据稀疏问题。</p>

<p>业界其他关于直接谈论胜出率和bid关系的论文就比较少了，但是方法论如出一辙，都是通过查询历史数据来调节特定流量或人群下的基准出价。</p>

<p><strong>出价函数建模</strong></p>

<p>有了以上的建模基础，我们可以针对每个候选广告计算CTR，然后搜索一个最佳的bid，最后按照收益最大的目标向AdExchange报价并投放对应的广告。这个方法的问题主要在于计算效率还不够高，因此现实中会继续把问题做简化，在报价精度与效率之间做trade off。</p>

<p>下面我们换一个角度探讨一下如何计算出价。我们不去显示建立winning_rate与bid的关系，而是把他隐含在出价里面，认为bid ~ (ad, user, context)。这样，可以离线建立一个模型，对于特定的用户、上下文和广告，直接判别式的计算出出价。这种计算方法其实是和收益目标最大化方法等价的，差别在于实现中可以经过各种简化和粗算，下面就介绍一下业界两家著名DSP的计算方法：</p>

<p><em>M6D</em></p>

<p>M6D是美国一家DSP公司，他们采取离线根据平均转化率avgCVR高低将用户划分成N个等级，每个等级被赋予一个基础出价；在线竞价过程中，先查找出该用户等级对应的基础出价avgBid，再根据实际投放广告和上下文，计算出真实转化率CVR，则最终出价为：</p>

<p>$bid = avgBid * (\frac{CVR}{avgCVR})^{\beta}$</p>

<p>这里 $\beta$ 一般是个阶梯函数，根据不同的CVR比值范围，跳跃性的取几个取值。这个模型可以看成是将出价因素分解为离线的用户基础出价和在线广告及上下文调整出价两部分，对winning_rate适配和收益目标的最大化体现在基础出价的制定和线上 $\beta$ 参数的调整。</p>

<p><em>一淘</em></p>

<p>一淘为了简化DSP出价的计算处理，提高报价效率，采用了只考虑流量属性估算出价，先报价后决策投放哪个广告的策略。我觉得这样做本身是有一定前提的：一是因为淘宝本身广告库极大，任何流量都能匹配出优质的广告，因此报价时考不考虑广告因素对最终结果影响不大；二是这样做等于把bid landscape只跟流量属性做关联，缓解了反馈数据的稀疏性问题。</p>

<p>在这一简化下，淘宝采用的是优化目标函数求解bid方法，先对AdExchange进行报价；如果竞价成功，则在AdExchange请求具体创意时，再对候选广告计算CVR，选择最佳创意。</p>

<p><strong>还是E&amp;E的问题</strong></p>

<p>在DSP向AdExchange报价这个任务中，面对的Explore&amp;Exploit问题更加突出，我们不但要面对CTR/CVR预估的冷启动，还要对新流量和新的竞争环境进行winning_rate的探索。一般是需要浪费一部分预算，对bid landscape覆盖不充分的流量进行报价，进一步探索出winning_rate，大体方法论上和CTR预估的E&amp;E差不多。</p>

<p>这里需要注意的是，探索的代价不只是浪费流量，同时需要浪费预算，这对于DSP的利润是有影响的（所以说搞不好DSP是要赔钱的）。一般市场上的DSP都采取谨慎的态度：或者控制出价公式，比如对用于Explore的出价要有另一套参数进行调控；或者控制流量，比如只对在DMP中能够匹配到user profile的流量进行报价，或者只在预算充分的情况下进行E&amp;E，并且要控制E&amp;E的pacing rate，探索过程将更加漫长。</p>

<p><strong>实践中的各种策略应对</strong></p>

<p><em>价格战</em></p>

<p>根据一淘披露的算法，会有一个bid_incr参数，用来调整预估出价与实际环境的bias，典型的应用就是价格战： $bid *= (1 + bid_incr)$</p>

<p><em>实时反馈</em></p>

<p>实时流可以及时调整bid landscape的准确率，反映环境的变化，对E&amp;E和预算控制是非常重要的，其实一切模型都应该考虑成有全量计算的和增量计算的两部分构成。</p>

<p><em>流量控制</em></p>

<p>主要目的是节约预算，使利润最大化，因此对于满足一定过滤条件的竞价机会（如：CTR低于一定阈值的情况），可以直接不竞价或出极低的价格。</p>

<p><em>频次控制</em></p>

<p>跟流量控制类似，防止短时间内对同类型的流量重复报价，用于节省预算。</p>

<p><em>广告隔离</em></p>

<p>在一些论文中，关于bid landscape以及如M6D的用户分级和基础出价都是针对每个广告计划独立制定的，这样可以更好的保护广告主的利益，使彼此的受众目标和投放数据做到隔离。这样做的缺点在于加大了数据的稀疏性，在条件允许下，我觉得把所有广告数据一起进行处理是更好的做法。</p>

<p>总结一下，出价模型并不像CTR预估一样纯粹，不能简单直接去hack model，系统性的支撑更为重要，技术上也更有挑战，效果的评估却也更加不易。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/">http://xuyuandong.github.io/blog/blog/2014/08/05/bid-model/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[广告在线投放中的排序与冷启动技术]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/"/>
    <updated>2014-08-02T12:21:21+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort</id>
    <content type="html"><![CDATA[<p>关于广告的在线投放技术，提及到策略和算法的东西可参考的并不像CTR预估那样多，原因主要还是和具体业务太相关，能够抽象出来的东西经过进一步简化，就比较少了；此外，由于学术圈比较难拿到真实数据，更难的是去做真实的大规模的实验，所以少了学术圈的推动，就难以热起来。但是，在工业界，线上策略对业务发展是非常重要的，并且会与工程、业务逻辑结合更加紧密，是公司里非常核心的技术。</p>

<p><strong>常见的扣费机制</strong></p>

<p>建立一个广告产品需要定义它的售卖对象、售卖方式和扣费机制（一种产品思维是把推荐也纳入到广告体系，甚至有人认为在移动互联网时代，可以把所有东西都认为是广告，即“产品即广告”；人们在消费信息，就是在消费广告，差异只在于这个信息是否有“buy”按钮，就是这条信息要不要触发扣费机制）。</p>

<p>首先，定义好售卖对象才能找到最匹配自己流量价值的广告主，定义好合适的售卖方式才能把广告主留住，帮广告主和自己找到共赢的合作方式。其中跟技术相关的就是扣费机制。按传统的几种方法来看，主要就是按CPM、CPC或者CPS来付费，对于常见的竞价广告系统来说，一般是在此基础上使用广义第二价格（GSP）计费。</p>

<p>刚接触广告的人一般看资料会误解为计费方式只有上面提到的几种，其实不是的，真正在商业领域会有各种各样不拘一格的广告扣费机制，核心目的是在提供流量资源（Supply）和产生的转化价值（Demand）之间找到双方认可的trade off；但是由于广告推广过程所涉及的多方（媒体、网络、广告主等）之间不能保证完全的信息透明，并且一旦涉及品牌效应和间接转化又无法量化衡量，所以才产生了或者偏向于Supply端、或者偏向于Demand端的扣费方式。</p>

<p>然后，我们在看一下竞价拍卖模式下的GSP扣费算法，排在第一位的成功竞拍者的扣费价格为出价第二高的价格加1个最小单位价格。对于广告来说呢？假设一个广告网络的竞价队列里同时存在以CPM/CPC/CPS扣费的广告，我们该如何排序？并如何计费呢？</p>

<p><strong>广告排序策略</strong></p>

<p>  <em>混合竞价</em></p>

<p>  上面提到一个很普遍存在的情况，即一个竞价队列中同时存在按CPM/CPC/CPS计费的广告，我们如何排序能够确保投放一个最优的广告呢？假设广告的出价都是广告主在预算了能够满足自己ROI前提下的价格，那么对于媒体或广告网络来说，从当前单次的曝光能够产生最大的收益的角度出发：<br/>
  CPM广告其收益为: Price{cpm} / 1000<br/>
  CPC广告其收益为: Price{cpc} * CTR <br/>
  CPS广告其收益为: Price{cps} * CTR * pCVR   <br/>
  我们将这三个可比拟的量统一称作eCPM，即effective CPM，其中CTR与pCVR是广告平台针对当前流量和当前投放的广告预估的点击率和点击后的转化率。</p>

<p>  <em>GSP计费一些讨论</em></p>

<p>  实际应用当中，不同的广告网络会对eCPM的计算有所变化，因为之前的公式是在流量资源被大量不同结算类型的广告主充分竞争情况下得出的结论，大家可以试想一下如果不满足这个条件，在GSP扣费原则下，会发生什么？对于天然CTR较低的广告位，会导致投CPC广告的客户居多，如果竞争不够充分，则出价高的广告主通过较低的GSP扣费就可以获得大量曝光；同理，对于天然CTR较高的广告位，投放CPM广告的客户可以利用较低的扣费赚取大量点击。</p>

<p>  此外，对于CPM广告，其决定排序的因素只有价格，所以广告主甚至可以出高价而不保证其广告创意对用户体验，这对媒体和广告网络的长期发展是极为不利的。因此，对不同计费类型的广告其eCPM计算可以略作修改的，一个常见的做法是：<br/>
$$
eCPM = Price * CTR^{\alpha} * pCVR^{\beta}
$$<br/>
其中，$ \alpha[cpm] = \alpha[cpc/cps] - 1, \beta[cpm/cpc] = \beta[cps] - 1 $ ，这里 $\alpha[cpc/cps]$ 和 $\beta[cps]$ 在默认条件下就是等于1的，可以通过微调 $\alpha, \beta$ 来控制CTR/CVR在不同类型计费广告中起的作用，从而让广告平台向用户体验好和对Demand端有利的广告有所倾斜。</p>

<p>  另外，对于GSP扣费，还有一个优美的统一公式，即：<br/>
$$
cost = Price * \frac{eCPM_2}{eCPM_1}
$$<br/>
无论何种类型的广告即排序顺序如何，都是可以套用的。这里还可以跟读者透露一个信息，即GSP只是绝大部分广告网络采样的扣费原则，目的是在按eCPM排序前提下，能够保证广告主自身无论如何调整出价，只要排名不变则其扣费就不会受到影响；这样，既能够保证广告网络的价格因素是稳定的，有利于把精力集中在受众定向的优化上，长期看还有利于广告网络整体竞争价格的上涨。</p>

<p><strong>冷启动问题</strong></p>

<p>按照上文的排序方案，一个直接的问题就是预估CTR或者CVR，但是无论是基于统计的方法还是基于模型的方法来预估CTR，前提是对候选广告有充分的投放样本可以参考。但是，实践中广告系统是高动态的，每日的新增广告比例还是很高的，这些没有投放记录的广告可以通过一些类似推荐中Content-based的方法估计出一个CTR分布，但是绝对不会很精确。因此，线上的投放策略一定要考虑到如何以最小的代价分配一些流量给新增广告，收集一些样本以便探索到新增广告的真实效果。</p>

<p>这方面在算法层面叫做“Explore &amp; Exploit”，即探索与开采，探索指浪费一部分流量投放非最优的新增广告进而收集其投放日志和分析它的投放效果，开采指在统计充分的广告中选择理论上最优的广告进行投放，两者之间是短期收入与长期利益的trade off。</p>

<p>这方面学术圈有大量的multi-arm bandit方面的论文从理论上讲如何做探索与开采，工业界比较好操作的策略大致我总结了以下三种：</p>

<p><strong>基于概率选择的E&amp;E策略</strong></p>

<p>长话短说，就是大家根据eCPM来排序，那么就根据eCPM来概率选择一个广告投放吧。优点是实现太简单了，能够做到大部分广告主都有消耗；缺点是毫无针对性，一是没有针对新增广告有目的的探索，二是没有针对短期收益做策略上的保障。</p>

<p><strong>基于置信度的E&amp;E策略</strong></p>

<p>一般是将广告按照曝光数量分为explore队列和exploit队列，然后设置一个explore比例，如果本次流量不需要做探索，则从exploit队列中选择最优广告进行投放；如果本次流量可以用来探索，则计算explore队列中每个广告的置信度，然后按置信度概率选择N个广告，再从N个广告中选择置信度最小（最需要探索的）进行投放。</p>

<p>这个策略来自雅虎的一篇论文《Exploitation and Exploration in a Performance based Contextual Advertising System》中被成为Confidence-based算法，其中置信度定义为 $tanh(frac{x}{b})$ ，x表示广告的曝光，b表示统计充分的阈值。</p>

<p>我认为该策略是有优点也存在未解决的问题的：优点在于策略的可控性，比如统计充分的阈值，探索的流量比例都是可调的；此外整个E&amp;E框架还可以进行扩展和修改，比如当前置信度概念只考虑了统计是否充分，如果不充分统计的广告其eCPM计算也有一定准确率，可以把eCPM等因素融入进去。这个策略的缺点在于，判断一个流量是否应该用于探索还是开采，纯粹是交给了随机数发生器，没有考虑当前的流量属性是否更适合探索还是开采，曝光是否充分的阈值也由经验决定，线上调参做实验成本高昂。</p>

<p><strong>基于Thompson采样的E&amp;E策略</strong></p>

<p>其实没有哪个E&amp;E框架能够在理论上证明是完美的，感觉这就是个实验科学话题，不过有的解决方案更偏工程化，有的解决方案会偏模型化。我认为Thompson采样策略是一个偏向于模型化的策略，它实际是个方法论，即CTR预估要估计出每个广告在当前流量下的CTR后验概率分布，然后按概率分布采样得到一个取值作为本次的预估CTR，整个排序和选择广告的过程是不需要有专门的探索或开采阶段的。</p>

<p>这看起来是个完美的解决方案，把任务直接交给CTR预估了。如果一个广告是统计充分的，那它的CTR后验概率分布形状应该非常尖锐（Sharp），统计期望CTR对应的概率密度应该非常大，这样采样的结果就大部分就是统计期望CTR；而如果一个广告是统计不充分的，那它的CTR后验概率分布形状将非常宽广（Wide），采样得到的结果会非常不集中，但随着样本积累越多，也会越来越接近统计平均。</p>

<p><em>Beta平滑</em></p>

<p>在使用统计方法做CTR预估的策略下，一般把统计似然的二项分布乘以先验beta分布做平滑，转化成后验beta分布 $B(a,b)$ ；所以，利用Thompson采样做CTR预估实际就是从beta分布中获得一个样本；当某个广告i被投放时，若有点击，则分布更新为 $B_i(a+1, b+1)$ ， 否则更新为 $B_i(a, b+1)$ ，下次采样则由更新后的分布决定；具体可以参考讲述统计平滑做CTR预估的博文。</p>

<p><em>LR模型</em></p>

<p>使用LR模型做CTR预估，CTR取值是由逻辑函数决定的，其统计不充分性来自于每个特征的学习样本是否充足；假设LR模型的损失函数使用L2正则化，则表示我们假设各维特征先验分布是高斯分布，学习模型时对每个特征权重的优化结果其实是特征的后验分布期望 $m_i$ ，我们还可以得到特征后验分布的标准差，如第i个特征 $ q_i = \sum_j<sup>n</sup> x_{ij}^2 p_j (1 - p_j) $ ，其中 $ p_j $ 是对样本j的CTR预测。</p>

<p>这样，整个Thompson采样过程其实就是对每个广告，取其每个特征i的分布 $N(m_i, q_i^{-1})$ ，对采样得到本次流量下该广告的特征采样值，进而计算该广告的CTR预估值。最终投放eCPM最大的，并按照投放结果是正样本还是负样本来更新每个特征的后验分布参数。</p>

<p>最后，需要补充的是，做好冷启动不能单纯看E&amp;E策略，还有更为重要的一环就是实时反馈，无论是统计还是模型，只有实时的把探索的效果反馈回系统，更正参数，才能引导系统向最优的方向运转，否则一切只是没有目标的低效率的探索而已。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/">http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[特征变换与离散化]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/"/>
    <updated>2014-07-23T12:23:52+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation</id>
    <content type="html"><![CDATA[<p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/">http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[点击率预估的机器学习模型及具体应用中的变种]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/"/>
    <updated>2014-07-16T12:21:57+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model</id>
    <content type="html"><![CDATA[<p>几乎所有涉及到CTR预估的文章都会用大篇幅谈论机器学习模型部分，有些模型非常复杂，常常会让人看了吓住，其实CTR预估本质无非就是“设计一个从特征到概率预测公式并套用在二项分布的损失函数中”这样一件任务而已。从这个角度理解，可以看到做好CTR预估机器学习模型有两个技术点：<br/>
（1）设计一个适应当下广告投放环境的预测概率公式<br/>
（2）根据(1)的设计得到的最优化问题进行数值求解<br/>
一般来讲，最常用的预测公式即是sigmod函数，最常用的模型即是LR模型，但是实际业务中简单的模型并不一定满足问题所处的场景，因此，下面我根据自己实际的业务经验，总结一下使用LR模型做CTR预估时常见的几个模型变种：</p>

<p><strong>位置偏置归一化</strong></p>

<p>除了单广告位或单页面只出一个广告的形式外，最常见的另一种广告展示形式是一个位置投放多条广告，比如百度的搜索广告或者新浪内容页右侧的文字链广告。在这种场景下，每个广告都有一个偏置特征，即排位。排位顺序靠前的广告被用户看到的机会更大，从而影响统计意义下的CTR；但是，在对日志分析和投放决策时，我们需要知道广告的天然CTR，不应该受到历史日志中投放偏置的影响。</p>

<p>对这个问题的处理有两种方法，一种就是之前讲CTR预估文章提到的把偏置特征和其他特征做交叉，预测时统一按照同一个排位来预测；但缺点是数据更稀疏了，有些广告没有投放过预测所用的排位时，结果偏差很大；另一种方法就是“位置归一化”，又叫position normalization。</p>

<p>我们把广告CTR的预测概率分解为：<br/>
p(click|i, j) = p(click|seen, i) * q(seen|j) = p[i]q[j]
其中，j 表示位置偏置，i 表示位置外其他用户、广告、上下文特征。</p>

<p>预测模型建立好后，根据点击事件满足二项分布 $c[ij] - Binomial (v[ij], p[i]q[j])$  可以带入二项分布的极大似然函数或负对数损失函数，简单对p、q求偏导，并使用EM算法得到p、q的一个解：</p>

<p>E-step: $q[j]^&lsquo; = \frac{\sum_i c[ij]}{ \sum_i (v[ij] - c[ij]) p[i] /(1 - p[i]q[j])}$</p>

<p>M-step: $p[i]^&lsquo; = \frac{\sum_j c[ij]}{ \sum_j (v[ij] - c[ij]) q[j] / (1 - p[i]q[j])}$</p>

<p>此外，还可以对模型进行进一步的假设和简化，当样本量n非常大，而点击率p非常小时， $Binomial(n,p) - Poisson(np)$ ，采样泊松分布的极大似然估计，结果会更加简单：</p>

<p>E-step: $q[j]^&lsquo; = \frac {\sum_i c[ij]}{\sum_i v[ij]p[i]}$</p>

<p>M-step: $p[i]^&lsquo; = \frac {\sum_j c[ij]}{\sum_j v[ij]q[j]}$</p>

<p>还可以对位置偏置因子q[j]加入先验概率，从而起到冷启动阶段对统计不充分的位置CTR做平滑的作用，对应于Poisson分布，可以选择Gamma分布的先验： $q[j] - Gamma(\alpha, \beta)$ ,进而再通过EM算法求解：</p>

<p>E-step: $q[j]^&lsquo; = \frac{\sum_i c[ij] + (\alpha - 1)}{\sum_i v[ij]p[i] + 1/\beta}$</p>

<p>M-step: $p[i]^&lsquo; = \frac{\sum_j c[ij]}{\sum_j v[ij]q[j]}$</p>

<p>其实，position normalization对我们最重要的意义是，提供了一种方法去估计位置偏置因子q[j]，有了这个因子，未必我们一定要使用上述的统计模型去预估CTR，我们还可以使用其他算法。比如使用LR模型，但是要注意的是，必须对LR学习的样本进行位置偏置因子的剥离，比如对曝光在位置j的样本，再训练模型前其权重需要做q[j]的衰减，而正样本应该增加其权重，这个归一化的思想是可以广泛适用的。</p>

<p><strong>带偏移量的LR模型</strong></p>

<p>还有一种非常常见的广告投放场景，如一个广告即可以投放到手机APP上，又可以投放到浏览器上，这样不同的流量平台会引入一些更复杂的偏置因素。与排位偏置不同，排位的场景是同一次广告请求下大家都能得到曝光机会，因此所有候选广告面对的用户、上下文特征分布情况是相同的；而这里所面对的情况是不同流量平台、或者不同网站来源等场景下，候选广告由于定向等因素，会有用户、上下文特征分布的差异，但是又有一定的相似，这样的条件下去建模CTR的预测公式。</p>

<p>大的概念上，这叫Transfer Learning，这是一种方法论层面的东西；在这里，我们简单的将CTR预测建模为偏移量的预测和广告自身预测的乘积：<br/>
$p(x,y|w,v) = p(x|w) * p(y|v)$<br/>
其中 p(x|w)和p(y|v)都用sigmod函数来建模，带入二项分布的负对数损失函数，在固定p(x|w)或固定p(y|v)的情况下，对w、v分别求偏导，可以得到EM的交替优化梯度。</p>

<p>如固定 $p(y|v) = \lambda_i$ (i与参数v维度数相关)，则
$$
L(w) = \sum_{ij} t (log \lambda_i - log(1 + exp(-x_j w))) + (1-t) log(1 - \lambda_i / (1 + exp(-x_j w)))
$$
对w求偏导可以得到对应的梯度：<br/>
$$
g(w) = \frac{p - t}{1 - p} \frac{x}{1 + exp(x_j w)} + gR(w)
$$
其中t是标签，p是预测，gR(w)表示正则项的导数，对v的操作是对称的。</p>

<p>如果将p(y|v)退化成排位偏置中的q，模型就退化成了position normalization；否则，v可以是表征流量平台相关的特征。在之前的CTR预估文章中，提到过这是个典型的多任务学习问题，这里的建模方法可以避免过多的交叉特征带来的数据稀疏性，同时能够让不同场景下的样本共有特征样本在同一个学习框架下学习，使学习更加充分。</p>

<p><strong>混合逻辑回归模型</strong></p>

<p>前面介绍的一些建模方法主要是应对业务场景问题，另一个CTR预估比较普遍的问题就是大规模特征下的非线性状态空间问题，说的直白点就是影响CTR的各种因素构成的状态空间中，CTR的概率分布是非线性的，而我们使用的LR模型本身是个广义线性模型，即各个特征参数是线性的组合在一起的。那么，面对高维非线性问题该怎么处理？</p>

<p>之前的文章我提到过做特征交叉，对用户、广告的特征做笛卡尔积，组合后放入线性模型，组合的越全面，对具体样本情况的描述越到位，但是却引来一系列问题：<br/>
(1)稀疏性，几十种特征组合后会形成几百万到上亿维度的稀疏二值特征<br/>
(2)过拟合，用户点击过的广告预估CTR高，看过点没点的CTR低<br/>
(3)单纯记忆历史，用户没看过的广告是否感兴趣很难预测</p>

<p>从特征角度去解决高维非线性问题是有上述一些问题的，因此需要从机器学习模型角度思考如何解决这些问题。一些已有的方法包括：<br/>
(1)Tree based方法<br/>
基于决策树的模型，如决策树、随机森林、GBDT等模型，因为树形结构是可以捕捉各类特征直接的相关性和状态空间的非线性的，各种基于树来演绎的模型主要是为了加强泛化能力和减少过拟合问题。<br/>
(2)矩阵分解<br/>
这种方法只能适合两种id的情况，如用户、广告，再加入其他独立的维度，就需要更复杂的解决方案了，关于结合了矩阵分解的各种演绎模型我们会单独在别的文章中介绍。<br/>
(3)混合模型<br/>
这种解决方案是考虑把一个非线性曲线拟合问题，转换成分段线性拟合问题；推广到高维状态空间，就是把整个非线性的空间用几个线性空间分片表示，每片区域是用线性模型预测的，再混合起来完整描述整体。具体的模型包括分片线性分类和混合逻辑回归两种：</p>

<p>分片线性分类： $p(y|x) = \frac{1}{1 + exp(-\sum_i \pi_i(x,u) (x w_i))}$</p>

<p>混合逻辑回归： $p(y|x) = \sum_i \pi_i(x,u) \frac{1}{1 + exp(-x w_i)}$</p>

<p>可见看出，分片线性分类是把非线性空间用一组线性模型分段拟合再混合表示，混合逻辑回归是对多个线性逻辑回归结果做非线性混合；它们的关键点时混合函数（分片函数、聚类函数），如：</p>

<p>$pi_i(x,u) = exp(-(x - c_i)<sup>T</sup> diag(u_i)(x - c_i))$</p>

<p>$pi_i(x,u) = exp(u_i * x)$</p>

<p>不过，复杂的建模往往面对的是困难的最优化求解过程，上式中不用做特征交叉，优化的变量减少了，但是却带来了M个聚类中心向量，假设每个混合成分对应的状态空间是N，则需要优化2N*M维变量，并且混合中心与特征向量两者一般还要用EM方法交替优化，偏导的公式也是很复杂的。</p>

<p><strong>FTRL-Proximal .&amp;. L-BFGS</strong></p>

<p>这里谈到的是两者优化算法，我们最熟悉的优化算法是SGD，即随机梯度下降；但是梯度下降算法比较不好解决的问题是“步长”，走快走慢都很大程度上影响最终结果；但好处是Online，即可以不记忆使用过的样本，在线的学习，能够收敛到一个还不错的结果。</p>

<p>Google基于SGD思想，设计了与其等价的FTRL-Proximal算法，主要的改进就是步长，一是给出了步长衰减的很靠谱的经验公式，并让各维特征的学习率随着他们的收敛情况自适应的变化，不需要统一使用固定的学习率。具体可以参考论文《Ad Click Prediction &ndash; a View from the Trenches》，由于文章写的实在太有可操作性，因此我这里就不再翻译一遍了。需要指出的是，Google的文章是基于LR模型做的公式推导，而FTRL本身是一种最优化方法，并不一定要拘泥于LR模型，还可以用于其他模型，用于替换基于SGD的优化算法。这一点是很重要的，这样我们就可以很方便的用于文章前面提到的各种复杂的模型参数求解。</p>

<p>另一个常用的优化算法是L-BFGS，是以损失函数的二阶导作为参数搜索方向，步长通过LineSearch的wolfe条件来决定。这个算法也是可谓历史悠久，相关的参考文献特别多，所以我这里也不做复制粘贴的工作了。L-BFGS更多的用于各种各样模型的优化求解中，一般都能给出靠谱的结果，所以抽象成黑盒的开源工具包夜很多，目前分布式的Spark MLlib也加入了支持。</p>

<p>对于广告CTR模型求解，我更加侧重FTRL，而非L-BFGS，一方面因为在线学习和学习速度的考虑，另一方面是因为L-BFGS需要一个SGD过程先初步寻参，大致找到比较靠谱的位置再用二阶导精确搜索，否则会立即陷入一个很差的局部最优解。</p>

<p><strong>ADMM</strong></p>

<p>ADMM（Alternating Direction Method of Multiplier）是一个分布式优化框架，这个框架比FTRL和L-BFGS更高一层次，就是说在部分数据集上可以使用任意优化算法来求最优参数，然后由ADMM这个框架负责把在分布式各个机器上的部分数据学习的结果融合成全局结果，迭代几次之后，这个全局解跟直接通过全量样本求解的结果是一致的，都是全局意义下的局部最优解。这在数据量非常大，不能单机求解的学习任务提供了一种方法。</p>

<p>对应于ADMM，L-BFGS也是可以分布式计算的，比如分布式去计算部分样本的梯度，再通过通信汇总得到全局梯度，但是这样其实是把一个算法给铺在了分布式上，通用性和扩展性都变差了，没有ADMM那样灵活。</p>

<p><strong>比赛中会用到的模型</strong></p>

<p>比赛中最常用的模型一般还是LR模型及其变种，Tree-based模型，以及矩阵分解；但是当数据集变得很少时，一些理论上比较完美的模型也常常拿来使用：</p>

<p><em>LearningToRank(RankNet)</em>  相当于把二项分布的损失函数改变了，将点击/不点击问题变成了排序问题，损失函数直接反映排位顺序；可以通过pair、list等粒度建立模型和损失函数，这一方向叫LearningToRank。</p>

<p><em>SVM</em>  比较经典的算法，比赛中面对小数据集常用来做模型，具有良好的防过拟合性质，但因为很难支持分布式，工业界较少使用。</p>

<p><em>Ensemble Model</em> 比赛中常会学习一大堆模型，然后再ensemble起来，工业界因为需要注重线上预测效率，所以比较少这么搞。对于工业界来讲，对数据和特征的加工处理往往要重于对模型的hack。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/">http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[基于模型的CTR预估与ETL]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/"/>
    <updated>2014-07-08T12:21:44+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl</id>
    <content type="html"><![CDATA[<hr />

<p>在广告和推荐业务中，让人感觉最核心和高大上的一块就是CTR（点击率）预估。基于机器学习模型的CTR预估，说白了就是利用已有的投放数据（包括曝光和点击日志）学习出一组参数表示的函数，输入我们认为对CTR有影响的因素（特征），函数给出我们一个估计出的CTR结果，因此，基于模型的CTR预估主要工作时对特征的研究和对模型的研究。</p>

<p>由于广告、搜索的业务每家公司都不太一样，涉及到的场景会有所区别，因此对问题的建模也会有所不同，这不但衍生出了机器学习模型本身的变化（我们将再另一篇里专门讨论），更多的不同都体现在了对业务数据的处理，即是对特征的处理，尽可能把问题在特征层面规约到几个标准化的机器学习问题上。这篇文章将以CTR预估最常用的LR模型为例，主要讨论在大数据情况下具体实战时，该怎么建立整个数据处理、模型训练和效果预估流程，这些更多是ETL层面的问题。</p>

<ul>
<li><strong>LR模型</strong></li>
</ul>


<p>有人问我为什么CTR预估最常用LR模型，我想先思考一下这个问题的特点：<br/>
1. 训练标签是离散的0或1<br/>
2. 输出要求是[0~1]之间的概率<br/>
3. 其他原因，如线性模型学习效率上的优点等</p>

<p>对于点击或不点击这种事情，天然满足二项分布的似然损失函数：<br/>
$$
-log(F) = -\frac{1}{n} \sum_{i=1}^n \left[y_i \log(p_i) + (1 - y_i)\log(1 - p_i)\right]
$$</p>

<p>其中二项分布中的预测概率是逻辑函数<br/>
$$
Pr(y=1|x,w) = \frac{1}{1 + exp(-w^{T}x)}<br/>
$$
时，这就是逻辑回归（LR）模型了。通常为了防止过拟合，会在损失函数上加入正则项，L2正则项相当于给二项分布似然函数加上了高斯分布的先验，L1正则项相当于加入拉普拉斯先验。此外，需要指出的是逻辑回归中使用的特征一般要求是二值类别特征，即0/1特征。</p>

<ul>
<li><strong>准备数据</strong></li>
</ul>


<p>对于CTR预估来讲，根据数据动态变化情况不同，需要准备短至7天，长达1年的训练数据；数据是按天分区的，首先要分析一下数据中每日新增的广告或商品的比例，以及数据中新增率、天然点击率的周期性，这些对于选择时间窗口是非常有意义的。</p>

<p>假如我们有8天的训练数据，选择时间窗口为7天，我们则按照时间先后顺序，将数据划分为训练集（前7天），测试集（后1天），对于机器学习领域提到的验证集（主要是用来调超参数用的），可以用训练集数据再划分做交叉验证的方法，或者直接划出部分测试集。</p>

<p>在实战中，一旦建立起模型并应用于线上，验证集一般就不需要了，除非模型除了大偏差需要重调，否则既浪费时间模型又不稳定。测试集一般也是不存在的，因为上线时总是希望用全部最新的数据去训练。Google提出过一种progressive validation的方法，使用Online Learning时可以边训练边测试评估，评估结果能够在一定程度上表征模型的好坏，我们再另一篇专门讨论模型的文章中会再提到。</p>

<p>由于上线后模型每天都要跑，所以数据的收集和整理一定要是增量式的，流程上采用一个滚动时间窗口的机制，可以减少处理数据的时间，加速模型的更新速度，提高效果。如果广告或商品的新增速度过快，每日更新模型都不足以保证效果的实时性，就需要小时级更新的模型或者实时模型；对于小时级模型，建议与每日模型分别批量训练并在使用策略上做模型混合；对于实时模型，整个ETL流程都是在线增量计算的，工程实现上会有较大区别，但思想上是一致，所以本文主要是谈批量的ETL处理流程。</p>

<ul>
<li><strong>数据格式</strong></li>
</ul>


<p>一般大公司都会用Hadoop家族的开源工具来管理自己的数据仓库，因此建议使用hive来管理自己的曝光、点击日志，生成的训练数据格式可以包括：0/1标签信息，曝光环境，广告信息，用户信息等四类信息。其中，<br/>
曝光环境包括：流量来源、网络环境、页面上下文属性等；<br/>
广告信息包括：广告和创意、广告计划、广告主的ID和相关属性，越具体越好；<br/>
用户信息包括：人口属性、短期长期兴趣标签、和当前广告的互动频次等，越具体越好；</p>

<ul>
<li><strong>特征处理</strong></li>
</ul>


<p>首先，需要明确偏置特征因子，怎么明确呢？想象一下我们的CTR预估使用场景，当某个广告位上某个用户访问时，需要从一组广告中选择一个CTR最高的投放出去，在这个场景下，曝光上下文环境和用户都是确定的，只有广告可以变化，所以上下文和用户特征就是偏置因子，它们对候选集合来说是不变的，只决定CTR的整体大小水平，不决定相对区分力。</p>

<p>单独把偏置因素纳入到训练数据的特征集合是没有意义的，因为在使用时它们不能起到区别作用。解决这个问题有2种方法，一种是在模型建模时就把偏置因素考虑进去，这将形成对LR模型的一个变种；另一种办法是把偏置因素和广告进行交叉组合，形成联合特征，每个联合的特征才能表示当前广告在特征偏置条件下的一个特征；考虑上下文-用户-广告的三联合甚至更多维的联合，将导致特征数量迅速膨胀，但每种特征都是很细化的一种情况，统计不一定充分，整体日志量相比特征集合大小也得不充分了，每条样本包含的特征数量占据整体特征集合非常小的一部分，这就形成了CTR预估的高维稀疏的数据问题，因而给机器学习领域造成了一定的挑战。</p>

<p>做特征处理时，我一般会先对样本的交叉特征出现的正负样本数进行统计，每一类交叉特征中识别出有容易造成过拟合的问题特征，进行过滤掉部分问题样本。对于不充分统计的特征，可以考虑进行按特征联合的层次进行聚类，不充分的特征归约到一起，如果整层都不充分就归约到上一层，这样不但可以降低特征维度，也可以防止这类特征权重学习不充分导致的过拟合。此外，对于连续数值形特征，需要做离散区间化处理，归为2值特征，这样一能减少特征维度，二能更好描述非线性状态空间。关于特征变换和离散化是一个可以进一步挖掘的问题，我将在另外一篇博客中单独来讨论。</p>

<p>下面我们考虑用MapReduce实现这个过程：可以考虑在Map阶段完成从原始训练数据按照配置文件进行联合交叉特征的生成，然后发送给Reduce阶段；可以设置Partition方法按照特征类别进行分区，在Reduce阶段设置Grouping方法把需要层次聚类的一组特征划到同一个reduce阶段，进而完成特征的聚类、特征变换和离散化处理等过程。</p>

<ul>
<li><strong>多任务学习</strong></li>
</ul>


<p>实际业务中，广告和商品投放在不同的流量来源位置是很常见的，不同位置带来的流量可能有2种情况：一是人群分布相同或相似，二是人群分布差异很大；</p>

<p>对于第一种情况，流量对应的人群差异不大，位置主要影响了曝光的可见性，造成点击率整体上有偏置差异，但对CTR的相对分布影响不大。这种问题建议修改建模方式，如采用transfer learning，position normalization之类的策略，能够利用上全部训练数据做模型学习，取得的效果会更好。这部分我将在专门讨论模型的文章中说明。</p>

<p>对于第二种情况，就需要分别做处理，比如分位置做训练，把每个位置的CTR预估看成一个独立的问题解决。其实，也可以一起训练，但是要求所有特征都要和位置ID做联合，这样可以在优化时起到隔离作用；这样可以在一次优化过程中完成多任务学习。</p>

<p><em>结合VW的训练过程</em></p>

<p>VW是Vowpal Wabbit缩写，是工业界常用的一个开源机器学习工具，支持在Hadoop上对大规模数据使用AllReduce方式分布式训练机器学习模型。使用VW需要将训练样本转换成其要求的格式，更多的详情可以参考：<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">https://github.com/JohnLangford/vowpal_wabbit/wiki</a></p>

<p>首先，我们需要把特征进行编号（特征ID化），目的是在优化损失函数时，各个维度互不冲突。使用MapReduce的处理方式，可以对上一小节的联合特征处理结果在Map阶段按照资源位置进行分发，在Reduce阶段顺序编号。这样可以保证同一个资源位（同一个学习任务）内的特征ID互不冲突，使用资源位ID作为特征名字空间，能够保证即使所有位置一起优化，也不会彼此干扰。</p>

<p>然后，我们使用ID化之后的特征对原始训练数据进行编码，生成VW需要的格式;因为特征文件也是很大规模的数据，因此需要用MapReduce的多路输入方式，按资源位进行分发，在Reduce阶段进行特征ID与样本数据的关联和格式转换，形成可用的样本。</p>

<p>最后，直接使用VW提供的脚本即可完成模型的学习。</p>

<ul>
<li><strong>样本倾斜</strong></li>
</ul>


<p>众所周知，广告或推荐的点击数据相比曝光数量是非常小的，这样我们的训练样本中正样本的比例也是非常小的（常常 &lt; 1%），这种情况被成为样本倾斜。一些机器学习算法是对正负样本比例敏感的，好在我们使用的逻辑回归模型并不如此。不过从以下几个角度考虑，我们还是要讨论一下负样本采样的重要性：<br/>
1. 降低训练数据的规模，加速模型学习过程<br/>
2. 负样本中抽样能够使训练过程泛化能力更强，有助于减少测试集上的误差<br/>
对于第二点，我认为主要是解决了非常不充分的噪声特征，减少了模型过拟合的可能性，但是绝大部分情况下良好的模型选择和数据清洗过程才是保证泛化能力的关键，因此加速模型学习效率是考虑样本下采样的关键因素。</p>

<p>对负样本的下采样其实是模型训练效率与准确率之间的一种trade off，原理上其实是不会改变预估结果的，负样本抽样的原理如下：<br/>
$$
\frac{P(y=1|x)}{P(y=-1|x)} = \frac{P(x|y=1)P(y=1)}{P(x|y=-1)P(y=-1)} = \frac{P&#8217;(x|y=1)P&#8217;(y=1)}{P&#8217;(x|y=-1)P(y=-1)/r} = r \frac{P&#8217;(y=1|x)}{P&#8217;(y=-1|x)}
$$<br/>
上面等式成立的前提是负样本采样不改变类别的条件概率分布：$P(x|y)=P&#8217;(x|y)$ 。这样，进行采样后，我们的负对数损失函数会被降低 $log r$ ，有2种办法解决这个问题：<br/>
1. 训练完成模型后，在预测时将模型权重线性加和后，在加上 $log r$ 做补偿；
2. 训练过程中，对采样后保留下来的负样本提升 $1/r$ 权重，从而保证损失函数不变；<br/>
实践中，第一种处理方法的泛化能力比较好，方法二得到的模型在测试集上并不理想，可能的解释是对样本进行重要性加权的做法会破坏了原本的泛化错误边界。</p>

<ul>
<li><strong>评价指标</strong></li>
</ul>


<p>评价点击率预估效果有几种方式可以参考：<br/>
1. <em>auROC</em> 最常见的评价方式，能够解释是否点击率预估的越高，覆盖的真实点击数比例越大；auROC除了常见的计算曲线覆盖面积方式外，还有一种有意思的计算方法：随机从样本集中取一个正样本和一个负样本，统计正样本预估CTR比负样本预估CTR高的概率，这也一定程度上解释了它的物理意义。 <br/>
auROC的问题是换一个数据集，当正负样本比例变了，评价值就没有可比性了；因此指标只能用于静态数据集上不同方法的实验对比。值得注意的是，单纯谈论auROC的大小是没有意义的，不一样的数据集，一个AUC=0.9，一个AUC=0.7，不能说明前者算法就比后者好。<br/>
2. <em>logLoss</em> 直接带入损失函数计算结果，因为二项分布是对称的，所以评价值对正负样本比例不敏感，对损失函数按样本数量做平均后，可以用于横向对比。不过，我觉得预测值的方差范围是会对评估结果有影响的，但是预测值方差范围也是算法的一个评价方面，因此不能说这是该评价指标的缺点。<br/>
以上两种都是比较核心的评价指标，此外，还有一些辅助性的效果监控方法，用于探测模型其他方面的问题：<br/>
3. <em>calibration</em> 我们把样本按预估点击率排序，在数轴上对预估点击率划分等长区间，每个区间内落入的样本数可以统计正样本比例（即该区间内真是点击率），这两个点击率分别绘制在二维左边系横轴和纵轴上，理论上应该是满足y=x的一条直线。实际上，围绕着y=x的波动范围体现出预估的方差，偏离程度预示着偏差，还可以看出模型在点击率高位预估的好还是低位预估的好，这往往预示着模型对如missing feature等因素处理的效果等问题。<br/>
此外，对每类特征都进行calibration监测是一个好方法，能够更细致的发现模型内部的问题。</p>

<ul>
<li><strong>特征选择</strong></li>
</ul>


<p>提到特征选择，一般有2种理解：一是特征类别的选择，二是特征取值的选择。学术界有一部分研究专门通过模型优化来进行特征选择，如L1正则化来进行特征取值的选择，L1/L2 group lasso方法同时进行特征类别和取值的选择；不过这类把所有问题都交给优化算法，一是会导致人工控制的不够，二是计算复杂性也是大大增加了，此外能够处理大规模数据的开源项目和工具还不成熟。其实，工业界中花人力最多的特征工程还是通过实验方法挖掘哪些类特征该加入模型，以及如何融入到已存在的一大堆特征类别中，达到最优的组合。</p>

<p>假如我们有N种特征，直观的方法是做O(2<sup>N</sup>)种选择构造候选特征集合，然后训练这么多个模型，选择效果最好的，代价是时间成本。如果要把指数实验次数降下来，可以考虑用动态规划的方法把实验次数降至O(N<sup>2</sup>)，我们这里介绍用贪心策略将实验次数降至O(N).</p>

<p>让人耳熟能详的特征选择方法，如互信息等，能够评价特征与分类任务的相关性，但是没有考虑到如果已经存在了一批特征之后，如何再往特征集合里添加新特征。我们现在将问题建模如下，假设存在一批特征构成的LR模型，其logLoss为：<br/>
$$
\sum_{i=1}^n log(1 + exp(-y_i s_i))
$$</p>

<p>对于要加入的特征 $W = [w_1, &hellip;, w_d]$ ，第i个样本的预测值则为 $s_i + w_i$ ，需要优化的损失函数为：
$$
logLoss = \sum_{i=1}^n log(1 + exp(-y_i (s_i + w_i)))
$$</p>

<p>进一步分解为（各 $w_k$ 独立优化）：
$$
logLoss = \sum_k \sum_i log(1 + exp(-y_i (s_i + w_k)))
$$
这样问题转化为确定s条件下优化w以使logLoss最小的问题。</p>

<p>可以跟进一次牛顿迭代估计出近似w的解： $w_k = - \frac{L_k^&lsquo;(0)}{L_k^&ldquo;(0)}$<br/>
其中，
$$
L_k^{&rsquo;}(0) = \sum_i p_i - \frac{y_i + 1}{2}
$$
$$
L_k^{&lsquo;&rsquo;}(0) = \sum_i p_i (1 - p_i)
$$
$$
p_i = \frac{1}{1 + exp(-s_i)}
$$</p>

<p>一旦w计算完成，我们可以估计出加入w特征后logLoss的改进值，
$$
\Delta logLoss = \sum_k w_k L_k^{&lsquo;}(0) + 0.5 w_{k}^2 L_k^{&rsquo;&lsquo;}(0)
$$
这个改进值可以视为新特征相对已有特征集合下对学习任务的条件互信息。</p>

<p>因此特征选择的过程可以归纳为如下算法： <br/>
（1）选择从一个基本特征集合开始<br/>
（2）对已有特征训练一个模型<br/>
（3）对待选择的特征逐一计算条件互信息( $\Delta logLoss$ ）<br/>
（4）选择 $\Delta logLoss$ 最小的，把对应特征加入已有特征集合<br/>
（5）重复（2）步</p>

<ul>
<li><p><strong>一些可以讨论的问题</strong></p>

<p><em>反馈特征</em><br/>
一些业界公司（如m6d，weibo）会实时统计如广告主、广告计划等各个维度的点击率，以及上下文和广告直接交叉维度的点击率，这些实时反馈的特征作为模型训练的特征。对于使用这类特征业界实际是有争议的：一种考虑是反馈特征统计口径界定容易造成生成的条件概率意义相对模糊，形成的连续数值特征离散化处理对最终效果影响较大，尤其是取值范围高位和地位孤立点很多，不易做好离散化。<br/>
反馈特征的一个特点是一旦广告或推荐系统平稳后，反馈取值范围也是稳定的，这样可以一次性完成ETL和模型训练过程，之后模型的权重很长时间都不会变化，即使变化也可以通过较小的代价以原模型权重为初值训练完成。这种方式很适合训练过程非常耗时，不能频繁更新模型的情况。</p>

<p><em>CTR .vs. CVR</em><br/>
转化率预估是比点击率预估正样本量更小的学习任务，因此样本倾斜、数据稀疏等问题都更加严重了。因此，常常吧转化率预估问题转化为点击率预估和点击后的转化率预估（pCVR预估），以减轻一些数据问题带来的严重性。
此外，转化率对特征的考虑也是不一样的，诸如上下文环境等和媒体相关的特征对最终的转化价值都大大降低，但用户基本属性与广告或商品属性的相关性特征对转化率起到大大的作用，这是需要仔细挖掘和分析的。</p>

<p><em>模型后处理</em><br/>
这里涉及的主要是missing feature的问题，当新样本的特征不在学习好的模型特征集合中时，逻辑函数计算 $\sum wx$ 的线性加和中某些项就查不到权重，这样估计值就会出现极大的偏差。解决这种主要是对原有特征按照类别和联合层次建立一个针对missing feature的查找体系，从而解决线上新特征的权重赋值问题。</p></li>
</ul>


<p>最后，本博客涉及的特征处理、采样、模型后处理等策略涉及的具体实现，可以参考本人的github项目：<a href="https://github.com/xuyuandong/mapreduce_etl/tree/master">https://github.com/xuyuandong/mapreduce_etl/tree/master</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/">http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[从GitHub启程]]></title>
    <link href="http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/"/>
    <updated>2014-07-05T14:51:57+08:00</updated>
    <id>http://xuyuandong.github.io/blog/blog/2014/07/05/post-title</id>
    <content type="html"><![CDATA[<hr />

<p>步入互联网行业早已超过三年，直到现在才开始建立自己的博客。在学校读书的时候虽然也有过几次写技术博客的日子，但都没有坚持下来，一是因为自己懒于把总结和整理的东西再编辑好发表出来，二是写着写着确实觉得才疏学浅，干货太少。工作之后，进度很快，也更忙碌了，一回首发现几年前接触的东西竟然快忘掉，电脑里只剩下一个个很难再去翻看的文件夹，于是发现，是时候该总结了。</p>

<p>回顾自己工作这几年，做过搜索、推荐、广告的系统架构和数据挖掘，但主要是在搜索、广告的一些关键技术和策略点上进行过深入的思考和开发，总结了一些面上的slides和点上code，这将在github这个平台上一一分享。特别感谢@Easy 让我有动力在github上开博客，而我电脑里这些沉积的资料也大部分是从工作过程中认识的内部的外部的同事朋友以及网络上感觉比较靠谱的分享中学习总结出来的，互联网的开放精神让这个行业飞快的进步，也让每个程序员都因此受益。</p>

<p>本篇我先粗描淡写讲一下如何用github打造个人blog，主要是援引网络上几个博客的内容。</p>

<ol>
<li><p>用github建立blog的原理  </br>
不错，用github写博客就像前端开发，这要从完整的博客系统角度理解。
博客系统需要一个类似CMS的博客站点管理部分，和一个后台的数据库，展示博客时系统会从数据库中获得内容动态形成HTML页面进行前端展示；然而，github和网上类似新浪博客的系统的区别是，他没有一个为博客定制的页面形成系统和数据库，但他是具有版本管理功能的代码仓库，所以我们只能通过把动态形成的页面变成静态页面，然后像代码一样提交给github，浏览博客是通过访问组织好的静态页面完成的。</p></li>
<li><p>配置ruby开发环境  </br>
<em>关键词：brew, ruby, rvm, rbenv, bundler</em><br/>
我个人不懂前端开发，所以也不太了解上面这些东西是什么，基本上就是照着网上一些文章照搬的，中间会发生不少错误，提示缺什么就装什么，基本能够搞定，我完成后看了一下自己的bash history，大致按照这么几条比较重要的命令：<br/>
[安装rvm]<br/>
<code>curl -sSL https://get.rvm.io | bash -s stable</code><br/>
[安装ruby]<br/>
<code>rvm install ruby-2.0.0-p594 &amp;&amp; rvm use 2.0.0</code><br/>
[安装brew]<br/>
<code>ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</code><br/>
<code>brew tab --repair</code><br/>
<code>brew update</code><br/>
[安装rbenv]<br/>
<code>brew install rbenv</code><br/>
<code>rbenv rehash</code><br/>
[按照bundler]<br/>
<code>gem update --system</code><br/>
<code>gem install bundler</code><br/>
<code>bundle install</code><br/>
到这里基本上装完了，不同系统由于曾经有过安装或者版本问题导致安装的过程都不会完全顺利，装成与否就看下一步octopress配置是否成功</p></li>
<li><p>配置和使用octopress  </br>
octopress是一个开发HTML静态页面网站的系统，在这个系统内我们只需要编辑MarkDown文件的内容就好了，页面风格主题之类的都交给octopress配置一下执行几个命令就能生成HTML静态页面网站，包括那些css，js文件等等，octopress可以和github关联起来，把静态页面网站提交给github，我们就可以通过github访问建好的博客站点了。<br/>
[注册个人github账号]<br/>
这一步就上github网站安装提示一步步来吧<br/>
[创建github上的blog项目]<br/>
按照这个链接来，有截图<a href="http://blog.csdn.net/renfufei/article/details/37725057  ">http://blog.csdn.net/renfufei/article/details/37725057  </a>
你会获得一个blog访问地址，比如：xxx.github.io/blog/<br/>
[下载并配置octopress]<br/>
<code>git clone git://github.com/imathis/octopress.git ~/dev/octopress</code> <br/>
<code>cd ~/dev/octopress</code>  <br/>
<code>rake install</code><br/>
<code>git remote add blog git@xxx.git</code> <br/>
[写第一篇blog]<br/>
<code>rake new_post["my first blog title"]</code><br/>
然后到~/dev/octopress/source/_posts/下找到对应的markdown文件编辑这篇博客<br/>
[生成静态网站]<br/>
<code>rake generate</code><br/>
[关联对应的git项目]<br/>
<code>rake setup_github_pages</code><br/>
[在4000端口预览]<br/>
<code>rake preview</code><br/>
[发布到github上]<br/>
<code>rake deploy</code></p></li>
</ol>


<p>到此大功告成，不过后面不断发布博客的过程中，还会遇到很多问题，比如git的版本管理问题，blog的格式问题，越多的问题就越要了解一些各方面的知识，比如git的使用，markdown语法，octopress的原理等等。</p>

<p>最后，希望本博客能够坚持写下去，发布更多搜索、推荐、广告、和数据挖掘相关内容！！！</p>

<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/'>http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/</a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'>http://xuyuandong.github.io/blog</a>
            </p>

]]></content>
  </entry>
  
</feed>
