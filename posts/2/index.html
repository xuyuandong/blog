
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Mr X&#8217;s blog</title>
  <meta name="author" content="XuYuandong">

  
  <meta name="description" content="关于广告的在线投放技术，提及到策略和算法的东西可参考的并不像CTR预估那样多，原因主要还是和具体业务太相关，能够抽象出来的东西经过进一步简化，就比较少了；此外，由于学术圈比较难拿到真实数据，更难的是去做真实的大规模的实验，所以少了学术圈的推动，就难以热起来。但是，在工业界， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://xuyuandong.github.io/blog/posts/2">
  <link href="/blog/favicon.png" rel="icon">
  <link href="/blog/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/blog/atom.xml" rel="alternate" title="Mr X's blog" type="application/atom+xml">
  <script src="/blog/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/blog/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/blog/">Mr X&#8217;s blog</a></h1>
  
    <h2>Taste the life and figure out the meaning</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/blog/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:xuyuandong.github.io/blog" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/blog/">Blog</a></li>
  <li><a href="/blog/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/08/02/explore-sort/">广告在线投放中的排序与冷启动技术</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-08-02T12:21:21+08:00'><span class='date'><span class='date-month'>Aug</span> <span class='date-day'>2</span><span class='date-suffix'>nd</span>, <span class='date-year'>2014</span></span> <span class='time'>12:21 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>关于广告的在线投放技术，提及到策略和算法的东西可参考的并不像CTR预估那样多，原因主要还是和具体业务太相关，能够抽象出来的东西经过进一步简化，就比较少了；此外，由于学术圈比较难拿到真实数据，更难的是去做真实的大规模的实验，所以少了学术圈的推动，就难以热起来。但是，在工业界，线上策略对业务发展是非常重要的，并且会与工程、业务逻辑结合更加紧密，是公司里非常核心的技术。</p>

<p><strong>常见的扣费机制</strong></p>

<p>建立一个广告产品需要定义它的售卖对象、售卖方式和扣费机制（一种产品思维是把推荐也纳入到广告体系，甚至有人认为在移动互联网时代，可以把所有东西都认为是广告，即“产品即广告”；人们在消费信息，就是在消费广告，差异只在于这个信息是否有“buy”按钮，就是这条信息要不要触发扣费机制）。</p>

<p>首先，定义好售卖对象才能找到最匹配自己流量价值的广告主，定义好合适的售卖方式才能把广告主留住，帮广告主和自己找到共赢的合作方式。其中跟技术相关的就是扣费机制。按传统的几种方法来看，主要就是按CPM、CPC或者CPS来付费，对于常见的竞价广告系统来说，一般是在此基础上使用广义第二价格（GSP）计费。</p>

<p>刚接触广告的人一般看资料会误解为计费方式只有上面提到的几种，其实不是的，真正在商业领域会有各种各样不拘一格的广告扣费机制，核心目的是在提供流量资源（Supply）和产生的转化价值（Demand）之间找到双方认可的trade off；但是由于广告推广过程所涉及的多方（媒体、网络、广告主等）之间不能保证完全的信息透明，并且一旦涉及品牌效应和间接转化又无法量化衡量，所以才产生了或者偏向于Supply端、或者偏向于Demand端的扣费方式。</p>

<p>然后，我们在看一下竞价拍卖模式下的GSP扣费算法，排在第一位的成功竞拍者的扣费价格为出价第二高的价格加1个最小单位价格。对于广告来说呢？假设一个广告网络的竞价队列里同时存在以CPM/CPC/CPS扣费的广告，我们该如何排序？并如何计费呢？</p>

<p><strong>广告排序策略</strong></p>

<p>  <em>混合竞价</em></p>

<p>  上面提到一个很普遍存在的情况，即一个竞价队列中同时存在按CPM/CPC/CPS计费的广告，我们如何排序能够确保投放一个最优的广告呢？假设广告的出价都是广告主在预算了能够满足自己ROI前提下的价格，那么对于媒体或广告网络来说，从当前单次的曝光能够产生最大的收益的角度出发：<br/>
  CPM广告其收益为: Price{cpm} / 1000<br/>
  CPC广告其收益为: Price{cpc} * CTR <br/>
  CPS广告其收益为: Price{cps} * CTR * pCVR   <br/>
  我们将这三个可比拟的量统一称作eCPM，即effective CPM，其中CTR与pCVR是广告平台针对当前流量和当前投放的广告预估的点击率和点击后的转化率。</p>

<p>  <em>GSP计费一些讨论</em></p>

<p>  实际应用当中，不同的广告网络会对eCPM的计算有所变化，因为之前的公式是在流量资源被大量不同结算类型的广告主充分竞争情况下得出的结论，大家可以试想一下如果不满足这个条件，在GSP扣费原则下，会发生什么？对于天然CTR较低的广告位，会导致投CPC广告的客户居多，如果竞争不够充分，则出价高的广告主通过较低的GSP扣费就可以获得大量曝光；同理，对于天然CTR较高的广告位，投放CPM广告的客户可以利用较低的扣费赚取大量点击。</p>

<p>  此外，对于CPM广告，其决定排序的因素只有价格，所以广告主甚至可以出高价而不保证其广告创意对用户体验，这对媒体和广告网络的长期发展是极为不利的。因此，对不同计费类型的广告其eCPM计算可以略作修改的，一个常见的做法是：<br/>
$$
eCPM = Price * CTR^{\alpha} * pCVR^{\beta}
$$<br/>
其中，$ \alpha[cpm] = \alpha[cpc/cps] - 1, \beta[cpm/cpc] = \beta[cps] - 1 $ ，这里 $\alpha[cpc/cps]$ 和 $\beta[cps]$ 在默认条件下就是等于1的，可以通过微调 $\alpha, \beta$ 来控制CTR/CVR在不同类型计费广告中起的作用，从而让广告平台向用户体验好和对Demand端有利的广告有所倾斜。</p>

<p>  另外，对于GSP扣费，还有一个优美的统一公式，即：<br/>
$$
cost = Price * \frac{eCPM_2}{eCPM_1}
$$<br/>
无论何种类型的广告即排序顺序如何，都是可以套用的。这里还可以跟读者透露一个信息，即GSP只是绝大部分广告网络采样的扣费原则，目的是在按eCPM排序前提下，能够保证广告主自身无论如何调整出价，只要排名不变则其扣费就不会受到影响；这样，既能够保证广告网络的价格因素是稳定的，有利于把精力集中在受众定向的优化上，长期看还有利于广告网络整体竞争价格的上涨。</p>

<p><strong>冷启动问题</strong></p>

<p>按照上文的排序方案，一个直接的问题就是预估CTR或者CVR，但是无论是基于统计的方法还是基于模型的方法来预估CTR，前提是对候选广告有充分的投放样本可以参考。但是，实践中广告系统是高动态的，每日的新增广告比例还是很高的，这些没有投放记录的广告可以通过一些类似推荐中Content-based的方法估计出一个CTR分布，但是绝对不会很精确。因此，线上的投放策略一定要考虑到如何以最小的代价分配一些流量给新增广告，收集一些样本以便探索到新增广告的真实效果。</p>

<p>这方面在算法层面叫做“Explore &amp; Exploit”，即探索与开采，探索指浪费一部分流量投放非最优的新增广告进而收集其投放日志和分析它的投放效果，开采指在统计充分的广告中选择理论上最优的广告进行投放，两者之间是短期收入与长期利益的trade off。</p>

<p>这方面学术圈有大量的multi-arm bandit方面的论文从理论上讲如何做探索与开采，工业界比较好操作的策略大致我总结了以下三种：</p>

<p><strong>基于概率选择的E&amp;E策略</strong></p>

<p>长话短说，就是大家根据eCPM来排序，那么就根据eCPM来概率选择一个广告投放吧。优点是实现太简单了，能够做到大部分广告主都有消耗；缺点是毫无针对性，一是没有针对新增广告有目的的探索，二是没有针对短期收益做策略上的保障。</p>

<p><strong>基于置信度的E&amp;E策略</strong></p>

<p>一般是将广告按照曝光数量分为explore队列和exploit队列，然后设置一个explore比例，如果本次流量不需要做探索，则从exploit队列中选择最优广告进行投放；如果本次流量可以用来探索，则计算explore队列中每个广告的置信度，然后按置信度概率选择N个广告，再从N个广告中选择置信度最小（最需要探索的）进行投放。</p>

<p>这个策略来自雅虎的一篇论文《Exploitation and Exploration in a Performance based Contextual Advertising System》中被成为Confidence-based算法，其中置信度定义为 $tanh(frac{x}{b})$ ，x表示广告的曝光，b表示统计充分的阈值。</p>

<p>我认为该策略是有优点也存在未解决的问题的：优点在于策略的可控性，比如统计充分的阈值，探索的流量比例都是可调的；此外整个E&amp;E框架还可以进行扩展和修改，比如当前置信度概念只考虑了统计是否充分，如果不充分统计的广告其eCPM计算也有一定准确率，可以把eCPM等因素融入进去。这个策略的缺点在于，判断一个流量是否应该用于探索还是开采，纯粹是交给了随机数发生器，没有考虑当前的流量属性是否更适合探索还是开采，曝光是否充分的阈值也由经验决定，线上调参做实验成本高昂。</p>

<p><strong>基于Thompson采样的E&amp;E策略</strong></p>

<p>其实没有哪个E&amp;E框架能够在理论上证明是完美的，感觉这就是个实验科学话题，不过有的解决方案更偏工程化，有的解决方案会偏模型化。我认为Thompson采样策略是一个偏向于模型化的策略，它实际是个方法论，即CTR预估要估计出每个广告在当前流量下的CTR后验概率分布，然后按概率分布采样得到一个取值作为本次的预估CTR，整个排序和选择广告的过程是不需要有专门的探索或开采阶段的。</p>

<p>这看起来是个完美的解决方案，把任务直接交给CTR预估了。如果一个广告是统计充分的，那它的CTR后验概率分布形状应该非常尖锐（Sharp），统计期望CTR对应的概率密度应该非常大，这样采样的结果就大部分就是统计期望CTR；而如果一个广告是统计不充分的，那它的CTR后验概率分布形状将非常宽广（Wide），采样得到的结果会非常不集中，但随着样本积累越多，也会越来越接近统计平均。</p>

<p><em>Beta平滑</em></p>

<p>在使用统计方法做CTR预估的策略下，一般把统计似然的二项分布乘以先验beta分布做平滑，转化成后验beta分布 $B(a,b)$ ；所以，利用Thompson采样做CTR预估实际就是从beta分布中获得一个样本；当某个广告i被投放时，若有点击，则分布更新为 $B_i(a+1, b+1)$ ， 否则更新为 $B_i(a, b+1)$ ，下次采样则由更新后的分布决定；具体可以参考讲述统计平滑做CTR预估的博文。</p>

<p><em>LR模型</em></p>

<p>使用LR模型做CTR预估，CTR取值是由逻辑函数决定的，其统计不充分性来自于每个特征的学习样本是否充足；假设LR模型的损失函数使用L2正则化，则表示我们假设各维特征先验分布是高斯分布，学习模型时对每个特征权重的优化结果其实是特征的后验分布期望 $m_i$ ，我们还可以得到特征后验分布的标准差，如第i个特征 $ q_i = \sum_j<sup>n</sup> x_{ij}^2 p_j (1 - p_j) $ ，其中 $ p_j $ 是对样本j的CTR预测。</p>

<p>这样，整个Thompson采样过程其实就是对每个广告，取其每个特征i的分布 $N(m_i, q_i^{-1})$ ，对采样得到本次流量下该广告的特征采样值，进而计算该广告的CTR预估值。最终投放eCPM最大的，并按照投放结果是正样本还是负样本来更新每个特征的后验分布参数。</p>

<p>最后，需要补充的是，做好冷启动不能单纯看E&amp;E策略，还有更为重要的一环就是实时反馈，无论是统计还是模型，只有实时的把探索的效果反馈回系统，更正参数，才能引导系统向最优的方向运转，否则一切只是没有目标的低效率的探索而已。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/'><a href="http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/">http://xuyuandong.github.io/blog/blog/2014/08/02/explore-sort/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/23/feature-transformation/">特征变换与离散化</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-07-23T12:23:52+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>23</span><span class='date-suffix'>rd</span>, <span class='date-year'>2014</span></span> <span class='time'>12:23 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>to be updated<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/">http://xuyuandong.github.io/blog/blog/2014/07/23/feature-transformation/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/16/prediction-model/">点击率预估的机器学习模型及具体应用中的变种</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-07-16T12:21:57+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>12:21 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>几乎所有涉及到CTR预估的文章都会用大篇幅谈论机器学习模型部分，有些模型非常复杂，常常会让人看了吓住，其实CTR预估本质无非就是“设计一个从特征到概率预测公式并套用在二项分布的损失函数中”这样一件任务而已。从这个角度理解，可以看到做好CTR预估机器学习模型有两个技术点：<br/>
（1）设计一个适应当下广告投放环境的预测概率公式<br/>
（2）根据(1)的设计得到的最优化问题进行数值求解<br/>
一般来讲，最常用的预测公式即是sigmod函数，最常用的模型即是LR模型，但是实际业务中简单的模型并不一定满足问题所处的场景，因此，下面我根据自己实际的业务经验，总结一下使用LR模型做CTR预估时常见的几个模型变种：</p>

<p><strong>位置偏置归一化</strong></p>

<p>除了单广告位或单页面只出一个广告的形式外，最常见的另一种广告展示形式是一个位置投放多条广告，比如百度的搜索广告或者新浪内容页右侧的文字链广告。在这种场景下，每个广告都有一个偏置特征，即排位。排位顺序靠前的广告被用户看到的机会更大，从而影响统计意义下的CTR；但是，在对日志分析和投放决策时，我们需要知道广告的天然CTR，不应该受到历史日志中投放偏置的影响。</p>

<p>对这个问题的处理有两种方法，一种就是之前讲CTR预估文章提到的把偏置特征和其他特征做交叉，预测时统一按照同一个排位来预测；但缺点是数据更稀疏了，有些广告没有投放过预测所用的排位时，结果偏差很大；另一种方法就是“位置归一化”，又叫position normalization。</p>

<p>我们把广告CTR的预测概率分解为：<br/>
p(click|i, j) = p(click|seen, i) * q(seen|j) = p[i]q[j]
其中，j 表示位置偏置，i 表示位置外其他用户、广告、上下文特征。</p>

<p>预测模型建立好后，根据点击事件满足二项分布 $c[ij] - Binomial (v[ij], p[i]q[j])$  可以带入二项分布的极大似然函数或负对数损失函数，简单对p、q求偏导，并使用EM算法得到p、q的一个解：</p>

<p>E-step: $q[j]^&lsquo; = \frac{\sum_i c[ij]}{ \sum_i (v[ij] - c[ij]) p[i] /(1 - p[i]q[j])}$</p>

<p>M-step: $p[i]^&lsquo; = \frac{\sum_j c[ij]}{ \sum_j (v[ij] - c[ij]) q[j] / (1 - p[i]q[j])}$</p>

<p>此外，还可以对模型进行进一步的假设和简化，当样本量n非常大，而点击率p非常小时， $Binomial(n,p) - Poisson(np)$ ，采样泊松分布的极大似然估计，结果会更加简单：</p>

<p>E-step: $q[j]^&lsquo; = \frac {\sum_i c[ij]}{\sum_i v[ij]p[i]}$</p>

<p>M-step: $p[i]^&lsquo; = \frac {\sum_j c[ij]}{\sum_j v[ij]q[j]}$</p>

<p>还可以对位置偏置因子q[j]加入先验概率，从而起到冷启动阶段对统计不充分的位置CTR做平滑的作用，对应于Poisson分布，可以选择Gamma分布的先验： $q[j] - Gamma(\alpha, \beta)$ ,进而再通过EM算法求解：</p>

<p>E-step: $q[j]^&lsquo; = \frac{\sum_i c[ij] + (\alpha - 1)}{\sum_i v[ij]p[i] + 1/\beta}$</p>

<p>M-step: $p[i]^&lsquo; = \frac{\sum_j c[ij]}{\sum_j v[ij]q[j]}$</p>

<p>其实，position normalization对我们最重要的意义是，提供了一种方法去估计位置偏置因子q[j]，有了这个因子，未必我们一定要使用上述的统计模型去预估CTR，我们还可以使用其他算法。比如使用LR模型，但是要注意的是，必须对LR学习的样本进行位置偏置因子的剥离，比如对曝光在位置j的样本，再训练模型前其权重需要做q[j]的衰减，而正样本应该增加其权重，这个归一化的思想是可以广泛适用的。</p>

<p><strong>带偏移量的LR模型</strong></p>

<p>还有一种非常常见的广告投放场景，如一个广告即可以投放到手机APP上，又可以投放到浏览器上，这样不同的流量平台会引入一些更复杂的偏置因素。与排位偏置不同，排位的场景是同一次广告请求下大家都能得到曝光机会，因此所有候选广告面对的用户、上下文特征分布情况是相同的；而这里所面对的情况是不同流量平台、或者不同网站来源等场景下，候选广告由于定向等因素，会有用户、上下文特征分布的差异，但是又有一定的相似，这样的条件下去建模CTR的预测公式。</p>

<p>大的概念上，这叫Transfer Learning，这是一种方法论层面的东西；在这里，我们简单的将CTR预测建模为偏移量的预测和广告自身预测的乘积：<br/>
$p(x,y|w,v) = p(x|w) * p(y|v)$<br/>
其中 p(x|w)和p(y|v)都用sigmod函数来建模，带入二项分布的负对数损失函数，在固定p(x|w)或固定p(y|v)的情况下，对w、v分别求偏导，可以得到EM的交替优化梯度。</p>

<p>如固定 $p(y|v) = \lambda_i$ (i与参数v维度数相关)，则
$$
L(w) = \sum_{ij} t (log \lambda_i - log(1 + exp(-x_j w))) + (1-t) log(1 - \lambda_i / (1 + exp(-x_j w)))
$$
对w求偏导可以得到对应的梯度：<br/>
$$
g(w) = \frac{p - t}{1 - p} \frac{x}{1 + exp(x_j w)} + gR(w)
$$
其中t是标签，p是预测，gR(w)表示正则项的导数，对v的操作是对称的。</p>

<p>如果将p(y|v)退化成排位偏置中的q，模型就退化成了position normalization；否则，v可以是表征流量平台相关的特征。在之前的CTR预估文章中，提到过这是个典型的多任务学习问题，这里的建模方法可以避免过多的交叉特征带来的数据稀疏性，同时能够让不同场景下的样本共有特征样本在同一个学习框架下学习，使学习更加充分。</p>

<p><strong>混合逻辑回归模型</strong></p>

<p>前面介绍的一些建模方法主要是应对业务场景问题，另一个CTR预估比较普遍的问题就是大规模特征下的非线性状态空间问题，说的直白点就是影响CTR的各种因素构成的状态空间中，CTR的概率分布是非线性的，而我们使用的LR模型本身是个广义线性模型，即各个特征参数是线性的组合在一起的。那么，面对高维非线性问题该怎么处理？</p>

<p>之前的文章我提到过做特征交叉，对用户、广告的特征做笛卡尔积，组合后放入线性模型，组合的越全面，对具体样本情况的描述越到位，但是却引来一系列问题：<br/>
(1)稀疏性，几十种特征组合后会形成几百万到上亿维度的稀疏二值特征<br/>
(2)过拟合，用户点击过的广告预估CTR高，看过点没点的CTR低<br/>
(3)单纯记忆历史，用户没看过的广告是否感兴趣很难预测</p>

<p>从特征角度去解决高维非线性问题是有上述一些问题的，因此需要从机器学习模型角度思考如何解决这些问题。一些已有的方法包括：<br/>
(1)Tree based方法<br/>
基于决策树的模型，如决策树、随机森林、GBDT等模型，因为树形结构是可以捕捉各类特征直接的相关性和状态空间的非线性的，各种基于树来演绎的模型主要是为了加强泛化能力和减少过拟合问题。<br/>
(2)矩阵分解<br/>
这种方法只能适合两种id的情况，如用户、广告，再加入其他独立的维度，就需要更复杂的解决方案了，关于结合了矩阵分解的各种演绎模型我们会单独在别的文章中介绍。<br/>
(3)混合模型<br/>
这种解决方案是考虑把一个非线性曲线拟合问题，转换成分段线性拟合问题；推广到高维状态空间，就是把整个非线性的空间用几个线性空间分片表示，每片区域是用线性模型预测的，再混合起来完整描述整体。具体的模型包括分片线性分类和混合逻辑回归两种：</p>

<p>分片线性分类： $p(y|x) = \frac{1}{1 + exp(-\sum_i \pi_i(x,u) (x w_i))}$</p>

<p>混合逻辑回归： $p(y|x) = \sum_i \pi_i(x,u) \frac{1}{1 + exp(-x w_i)}$</p>

<p>可见看出，分片线性分类是把非线性空间用一组线性模型分段拟合再混合表示，混合逻辑回归是对多个线性逻辑回归结果做非线性混合；它们的关键点时混合函数（分片函数、聚类函数），如：</p>

<p> $\pi_i(x,u) = exp(-(x - u_i)<sup>2</sup>)$</p>

<p> $\pi_i(x,u) = exp(u_i * x)$</p>

<p>不过，复杂的建模往往面对的是困难的最优化求解过程，上式中不用做特征交叉，优化的变量减少了，但是却带来了M个聚类中心向量，假设每个混合成分对应的状态空间是N，则需要优化2N*M维变量，并且混合中心与特征向量两者一般还要用EM方法交替优化，偏导的公式也是很复杂的。</p>

<p><strong>FTRL-Proximal .&amp;. L-BFGS</strong></p>

<p>这里谈到的是两者优化算法，我们最熟悉的优化算法是SGD，即随机梯度下降；但是梯度下降算法比较不好解决的问题是“步长”，走快走慢都很大程度上影响最终结果；但好处是Online，即可以不记忆使用过的样本，在线的学习，能够收敛到一个还不错的结果。</p>

<p>Google基于SGD思想，设计了与其等价的FTRL-Proximal算法，主要的改进就是步长，一是给出了步长衰减的很靠谱的经验公式，并让各维特征的学习率随着他们的收敛情况自适应的变化，不需要统一使用固定的学习率。具体可以参考论文《Ad Click Prediction &ndash; a View from the Trenches》，由于文章写的实在太有可操作性，因此我这里就不再翻译一遍了。需要指出的是，Google的文章是基于LR模型做的公式推导，而FTRL本身是一种最优化方法，并不一定要拘泥于LR模型，还可以用于其他模型，用于替换基于SGD的优化算法。这一点是很重要的，这样我们就可以很方便的用于文章前面提到的各种复杂的模型参数求解。</p>

<p>另一个常用的优化算法是L-BFGS，是以损失函数的二阶导作为参数搜索方向，步长通过LineSearch的wolfe条件来决定。这个算法也是可谓历史悠久，相关的参考文献特别多，所以我这里也不做复制粘贴的工作了。L-BFGS更多的用于各种各样模型的优化求解中，一般都能给出靠谱的结果，所以抽象成黑盒的开源工具包夜很多，目前分布式的Spark MLlib也加入了支持。</p>

<p>对于广告CTR模型求解，我更加侧重FTRL，而非L-BFGS，一方面因为在线学习和学习速度的考虑，另一方面是因为L-BFGS需要一个SGD过程先初步寻参，大致找到比较靠谱的位置再用二阶导精确搜索，否则会立即陷入一个很差的局部最优解。</p>

<p><strong>ADMM</strong></p>

<p>ADMM（Alternating Direction Method of Multiplier）是一个分布式优化框架，这个框架比FTRL和L-BFGS更高一层次，就是说在部分数据集上可以使用任意优化算法来求最优参数，然后由ADMM这个框架负责把在分布式各个机器上的部分数据学习的结果融合成全局结果，迭代几次之后，这个全局解跟直接通过全量样本求解的结果是一致的，都是全局意义下的局部最优解。这在数据量非常大，不能单机求解的学习任务提供了一种方法。</p>

<p>ADMM问题形式如：</p>

<p>$minimize  f(x) + g(z)  subject to  Ax + Bz = c  with f and g convex$</p>

<p>等价的增广的拉格朗日形式如：</p>

<p> $L(x,z,y) = f(x) + g(z) + y<sup>T</sup>(Ax + Bz - c) + \frac{\rho}{2}(Ax + Bz -c)<sup>2</sup>$</p>

<p>设 $u = y<sup>T</sup>/\rho$ 后，对数据分布在N个节点下的情况下求解可以表示为：</p>

<p> $x_j^{k+1} = argmin(f_j(x_j) + \frac{\rho}{2}(x_j - z<sup>k</sup> + u_j<sup>k</sup>)<sup>2</sup>)$</p>

<p>表示每个 $x_j$ 可以在自己所在的那个节点数据上独立求解；</p>

<p> $z^{k+1} = argmin(g(z) + \frac{N\rho}{2}(z - x^{k+1} + u<sup>k</sup>)<sup>2</sup>)$</p>

<p>表示 $z$ 需要使用所有节点的 $x$ 进行全局求解；</p>

<p> $u_j^{k+1} = u_j<sup>k</sup> + x_j^{k+1} - z^{k+1}$</p>

<p>表示 $u$ 可以在各个节点上使用自身的 $x$ 和全局的 $z$ 独立进行更新；</p>

<p>对于LR模型，转化成ADMM的形式即：</p>

<p> $f(w) = \frac{1}{m} \sum log(1 + exp(-y_i * w x_i))$</p>

<p>和</p>

<p> $g(z) = \lambda ||z||^2$</p>

<p>约束条件为： $w - z = 0$</p>

<p>这样就可以使用上面推导的交替迭代求解公式进行求解，求解过程中，只需要在各节点上独立优化 $w_j$ ，然后聚合到一台机器上全局优化 $z$ ，最后在各节点上独立更新 $u$ ，其中 $z$ 的优化是可通过求导得到闭式解的， $w$ 的优化可视为单机版的优化问题，可以使用FTRL或L-BFGS等各种单机算法。</p>

<p>在分布式优化方面，L-BFGS算法也是可以扩展到分布式情况的，比如分布式去计算部分样本的梯度，再通过通信汇总得到全局梯度，这样是把一个算法给铺在了分布式上，但是却感觉没有ADMM那样通用和灵活。</p>

<p><strong>比赛中会用到的模型</strong></p>

<p>比赛中最常用的模型一般还是LR模型及其变种，Tree-based模型，以及矩阵分解；但是当数据集变得很少时，一些理论上比较完美的模型也常常拿来使用：</p>

<p><em>LearningToRank(RankNet)</em>  相当于把二项分布的损失函数改变了，将点击/不点击问题变成了排序问题，损失函数直接反映排位顺序；可以通过pair、list等粒度建立模型和损失函数，这一方向叫LearningToRank。</p>

<p><em>SVM</em>  比较经典的算法，比赛中面对小数据集常用来做模型，具有良好的防过拟合性质，但因为很难支持分布式，工业界较少使用。</p>

<p><em>Ensemble Model</em> 比赛中常会学习一大堆模型，然后再ensemble起来，工业界因为需要注重线上预测效率，所以比较少这么搞。对于工业界来讲，对数据和特征的加工处理往往要重于对模型的hack。<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/">http://xuyuandong.github.io/blog/blog/2014/07/16/prediction-model/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/08/model-etl/">基于模型的CTR预估与ETL</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-07-08T12:21:44+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>12:21 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><hr />

<p>在广告和推荐业务中，让人感觉最核心和高大上的一块就是CTR（点击率）预估。基于机器学习模型的CTR预估，说白了就是利用已有的投放数据（包括曝光和点击日志）学习出一组参数表示的函数，输入我们认为对CTR有影响的因素（特征），函数给出我们一个估计出的CTR结果，因此，基于模型的CTR预估主要工作时对特征的研究和对模型的研究。</p>

<p>由于广告、搜索的业务每家公司都不太一样，涉及到的场景会有所区别，因此对问题的建模也会有所不同，这不但衍生出了机器学习模型本身的变化（我们将再另一篇里专门讨论），更多的不同都体现在了对业务数据的处理，即是对特征的处理，尽可能把问题在特征层面规约到几个标准化的机器学习问题上。这篇文章将以CTR预估最常用的LR模型为例，主要讨论在大数据情况下具体实战时，该怎么建立整个数据处理、模型训练和效果预估流程，这些更多是ETL层面的问题。</p>

<ul>
<li><strong>LR模型</strong></li>
</ul>


<p>有人问我为什么CTR预估最常用LR模型，我想先思考一下这个问题的特点：<br/>
1. 训练标签是离散的0或1<br/>
2. 输出要求是[0~1]之间的概率<br/>
3. 其他原因，如线性模型学习效率上的优点等</p>

<p>对于点击或不点击这种事情，天然满足二项分布的似然损失函数：<br/>
$$
-log(F) = -\frac{1}{n} \sum_{i=1}^n \left[y_i \log(p_i) + (1 - y_i)\log(1 - p_i)\right]
$$</p>

<p>其中二项分布中的预测概率是逻辑函数<br/>
$$
Pr(y=1|x,w) = \frac{1}{1 + exp(-w^{T}x)}<br/>
$$
时，这就是逻辑回归（LR）模型了。通常为了防止过拟合，会在损失函数上加入正则项，L2正则项相当于给二项分布似然函数加上了高斯分布的先验，L1正则项相当于加入拉普拉斯先验。此外，需要指出的是逻辑回归中使用的特征一般要求是二值类别特征，即0/1特征。</p>

<ul>
<li><strong>准备数据</strong></li>
</ul>


<p>对于CTR预估来讲，根据数据动态变化情况不同，需要准备短至7天，长达1年的训练数据；数据是按天分区的，首先要分析一下数据中每日新增的广告或商品的比例，以及数据中新增率、天然点击率的周期性，这些对于选择时间窗口是非常有意义的。</p>

<p>假如我们有8天的训练数据，选择时间窗口为7天，我们则按照时间先后顺序，将数据划分为训练集（前7天），测试集（后1天），对于机器学习领域提到的验证集（主要是用来调超参数用的），可以用训练集数据再划分做交叉验证的方法，或者直接划出部分测试集。</p>

<p>在实战中，一旦建立起模型并应用于线上，验证集一般就不需要了，除非模型除了大偏差需要重调，否则既浪费时间模型又不稳定。测试集一般也是不存在的，因为上线时总是希望用全部最新的数据去训练。Google提出过一种progressive validation的方法，使用Online Learning时可以边训练边测试评估，评估结果能够在一定程度上表征模型的好坏，我们再另一篇专门讨论模型的文章中会再提到。</p>

<p>由于上线后模型每天都要跑，所以数据的收集和整理一定要是增量式的，流程上采用一个滚动时间窗口的机制，可以减少处理数据的时间，加速模型的更新速度，提高效果。如果广告或商品的新增速度过快，每日更新模型都不足以保证效果的实时性，就需要小时级更新的模型或者实时模型；对于小时级模型，建议与每日模型分别批量训练并在使用策略上做模型混合；对于实时模型，整个ETL流程都是在线增量计算的，工程实现上会有较大区别，但思想上是一致，所以本文主要是谈批量的ETL处理流程。</p>

<ul>
<li><strong>数据格式</strong></li>
</ul>


<p>一般大公司都会用Hadoop家族的开源工具来管理自己的数据仓库，因此建议使用hive来管理自己的曝光、点击日志，生成的训练数据格式可以包括：0/1标签信息，曝光环境，广告信息，用户信息等四类信息。其中，<br/>
曝光环境包括：流量来源、网络环境、页面上下文属性等；<br/>
广告信息包括：广告和创意、广告计划、广告主的ID和相关属性，越具体越好；<br/>
用户信息包括：人口属性、短期长期兴趣标签、和当前广告的互动频次等，越具体越好；</p>

<ul>
<li><strong>特征处理</strong></li>
</ul>


<p>首先，需要明确偏置特征因子，怎么明确呢？想象一下我们的CTR预估使用场景，当某个广告位上某个用户访问时，需要从一组广告中选择一个CTR最高的投放出去，在这个场景下，曝光上下文环境和用户都是确定的，只有广告可以变化，所以上下文和用户特征就是偏置因子，它们对候选集合来说是不变的，只决定CTR的整体大小水平，不决定相对区分力。</p>

<p>单独把偏置因素纳入到训练数据的特征集合是没有意义的，因为在使用时它们不能起到区别作用。解决这个问题有2种方法，一种是在模型建模时就把偏置因素考虑进去，这将形成对LR模型的一个变种；另一种办法是把偏置因素和广告进行交叉组合，形成联合特征，每个联合的特征才能表示当前广告在特征偏置条件下的一个特征；考虑上下文-用户-广告的三联合甚至更多维的联合，将导致特征数量迅速膨胀，但每种特征都是很细化的一种情况，统计不一定充分，整体日志量相比特征集合大小也得不充分了，每条样本包含的特征数量占据整体特征集合非常小的一部分，这就形成了CTR预估的高维稀疏的数据问题，因而给机器学习领域造成了一定的挑战。</p>

<p>做特征处理时，我一般会先对样本的交叉特征出现的正负样本数进行统计，每一类交叉特征中识别出有容易造成过拟合的问题特征，进行过滤掉部分问题样本。对于不充分统计的特征，可以考虑进行按特征联合的层次进行聚类，不充分的特征归约到一起，如果整层都不充分就归约到上一层，这样不但可以降低特征维度，也可以防止这类特征权重学习不充分导致的过拟合。此外，对于连续数值形特征，需要做离散区间化处理，归为2值特征，这样一能减少特征维度，二能更好描述非线性状态空间。关于特征变换和离散化是一个可以进一步挖掘的问题，我将在另外一篇博客中单独来讨论。</p>

<p>下面我们考虑用MapReduce实现这个过程：可以考虑在Map阶段完成从原始训练数据按照配置文件进行联合交叉特征的生成，然后发送给Reduce阶段；可以设置Partition方法按照特征类别进行分区，在Reduce阶段设置Grouping方法把需要层次聚类的一组特征划到同一个reduce阶段，进而完成特征的聚类、特征变换和离散化处理等过程。</p>

<ul>
<li><strong>多任务学习</strong></li>
</ul>


<p>实际业务中，广告和商品投放在不同的流量来源位置是很常见的，不同位置带来的流量可能有2种情况：一是人群分布相同或相似，二是人群分布差异很大；</p>

<p>对于第一种情况，流量对应的人群差异不大，位置主要影响了曝光的可见性，造成点击率整体上有偏置差异，但对CTR的相对分布影响不大。这种问题建议修改建模方式，如采用transfer learning，position normalization之类的策略，能够利用上全部训练数据做模型学习，取得的效果会更好。这部分我将在专门讨论模型的文章中说明。</p>

<p>对于第二种情况，就需要分别做处理，比如分位置做训练，把每个位置的CTR预估看成一个独立的问题解决。其实，也可以一起训练，但是要求所有特征都要和位置ID做联合，这样可以在优化时起到隔离作用；这样可以在一次优化过程中完成多任务学习。</p>

<p><em>结合VW的训练过程</em></p>

<p>VW是Vowpal Wabbit缩写，是工业界常用的一个开源机器学习工具，支持在Hadoop上对大规模数据使用AllReduce方式分布式训练机器学习模型。使用VW需要将训练样本转换成其要求的格式，更多的详情可以参考：<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">https://github.com/JohnLangford/vowpal_wabbit/wiki</a></p>

<p>首先，我们需要把特征进行编号（特征ID化），目的是在优化损失函数时，各个维度互不冲突。使用MapReduce的处理方式，可以对上一小节的联合特征处理结果在Map阶段按照资源位置进行分发，在Reduce阶段顺序编号。这样可以保证同一个资源位（同一个学习任务）内的特征ID互不冲突，使用资源位ID作为特征名字空间，能够保证即使所有位置一起优化，也不会彼此干扰。</p>

<p>然后，我们使用ID化之后的特征对原始训练数据进行编码，生成VW需要的格式;因为特征文件也是很大规模的数据，因此需要用MapReduce的多路输入方式，按资源位进行分发，在Reduce阶段进行特征ID与样本数据的关联和格式转换，形成可用的样本。</p>

<p>最后，直接使用VW提供的脚本即可完成模型的学习。</p>

<ul>
<li><strong>样本倾斜</strong></li>
</ul>


<p>众所周知，广告或推荐的点击数据相比曝光数量是非常小的，这样我们的训练样本中正样本的比例也是非常小的（常常 &lt; 1%），这种情况被成为样本倾斜。一些机器学习算法是对正负样本比例敏感的，好在我们使用的逻辑回归模型并不如此。不过从以下几个角度考虑，我们还是要讨论一下负样本采样的重要性：<br/>
1. 降低训练数据的规模，加速模型学习过程<br/>
2. 负样本中抽样能够使训练过程泛化能力更强，有助于减少测试集上的误差<br/>
对于第二点，我认为主要是解决了非常不充分的噪声特征，减少了模型过拟合的可能性，但是绝大部分情况下良好的模型选择和数据清洗过程才是保证泛化能力的关键，因此加速模型学习效率是考虑样本下采样的关键因素。</p>

<p>对负样本的下采样其实是模型训练效率与准确率之间的一种trade off，原理上其实是不会改变预估结果的，负样本抽样的原理如下：<br/>
$$
\frac{P(y=1|x)}{P(y=-1|x)} = \frac{P(x|y=1)P(y=1)}{P(x|y=-1)P(y=-1)} = \frac{P&#8217;(x|y=1)P&#8217;(y=1)}{P&#8217;(x|y=-1)P(y=-1)/r} = r \frac{P&#8217;(y=1|x)}{P&#8217;(y=-1|x)}
$$<br/>
上面等式成立的前提是负样本采样不改变类别的条件概率分布：$P(x|y)=P&#8217;(x|y)$ 。这样，进行采样后，我们的负对数损失函数会被降低 $log r$ ，有2种办法解决这个问题：<br/>
1. 训练完成模型后，在预测时将模型权重线性加和后，在加上 $log r$ 做补偿；
2. 训练过程中，对采样后保留下来的负样本提升 $1/r$ 权重，从而保证损失函数不变；<br/>
实践中，第一种处理方法的泛化能力比较好，方法二得到的模型在测试集上并不理想，可能的解释是对样本进行重要性加权的做法会破坏了原本的泛化错误边界。</p>

<ul>
<li><strong>评价指标</strong></li>
</ul>


<p>评价点击率预估效果有几种方式可以参考：<br/>
1. <em>auROC</em> 最常见的评价方式，能够解释是否点击率预估的越高，覆盖的真实点击数比例越大；auROC除了常见的计算曲线覆盖面积方式外，还有一种有意思的计算方法：随机从样本集中取一个正样本和一个负样本，统计正样本预估CTR比负样本预估CTR高的概率，这也一定程度上解释了它的物理意义。 <br/>
auROC的问题是换一个数据集，当正负样本比例变了，评价值就没有可比性了；因此指标只能用于静态数据集上不同方法的实验对比。值得注意的是，单纯谈论auROC的大小是没有意义的，不一样的数据集，一个AUC=0.9，一个AUC=0.7，不能说明前者算法就比后者好。<br/>
2. <em>logLoss</em> 直接带入损失函数计算结果，因为二项分布是对称的，所以评价值对正负样本比例不敏感，对损失函数按样本数量做平均后，可以用于横向对比。不过，我觉得预测值的方差范围是会对评估结果有影响的，但是预测值方差范围也是算法的一个评价方面，因此不能说这是该评价指标的缺点。<br/>
以上两种都是比较核心的评价指标，此外，还有一些辅助性的效果监控方法，用于探测模型其他方面的问题：<br/>
3. <em>calibration</em> 我们把样本按预估点击率排序，在数轴上对预估点击率划分等长区间，每个区间内落入的样本数可以统计正样本比例（即该区间内真是点击率），这两个点击率分别绘制在二维左边系横轴和纵轴上，理论上应该是满足y=x的一条直线。实际上，围绕着y=x的波动范围体现出预估的方差，偏离程度预示着偏差，还可以看出模型在点击率高位预估的好还是低位预估的好，这往往预示着模型对如missing feature等因素处理的效果等问题。<br/>
此外，对每类特征都进行calibration监测是一个好方法，能够更细致的发现模型内部的问题。</p>

<ul>
<li><strong>特征选择</strong></li>
</ul>


<p>提到特征选择，一般有2种理解：一是特征类别的选择，二是特征取值的选择。学术界有一部分研究专门通过模型优化来进行特征选择，如L1正则化来进行特征取值的选择，L1/L2 group lasso方法同时进行特征类别和取值的选择；不过这类把所有问题都交给优化算法，一是会导致人工控制的不够，二是计算复杂性也是大大增加了，此外能够处理大规模数据的开源项目和工具还不成熟。其实，工业界中花人力最多的特征工程还是通过实验方法挖掘哪些类特征该加入模型，以及如何融入到已存在的一大堆特征类别中，达到最优的组合。</p>

<p>假如我们有N种特征，直观的方法是做O(2<sup>N</sup>)种选择构造候选特征集合，然后训练这么多个模型，选择效果最好的，代价是时间成本。如果要把指数实验次数降下来，可以考虑用动态规划的方法把实验次数降至O(N<sup>2</sup>)，我们这里介绍用贪心策略将实验次数降至O(N).</p>

<p>让人耳熟能详的特征选择方法，如互信息等，能够评价特征与分类任务的相关性，但是没有考虑到如果已经存在了一批特征之后，如何再往特征集合里添加新特征。我们现在将问题建模如下，假设存在一批特征构成的LR模型，其logLoss为：<br/>
$$
\sum_{i=1}^n log(1 + exp(-y_i s_i))
$$</p>

<p>对于要加入的特征 $W = [w_1, &hellip;, w_d]$ ，第i个样本的预测值则为 $s_i + w_i$ ，需要优化的损失函数为：
$$
logLoss = \sum_{i=1}^n log(1 + exp(-y_i (s_i + w_i)))
$$</p>

<p>进一步分解为（各 $w_k$ 独立优化）：
$$
logLoss = \sum_k \sum_i log(1 + exp(-y_i (s_i + w_k)))
$$
这样问题转化为确定s条件下优化w以使logLoss最小的问题。</p>

<p>可以跟进一次牛顿迭代估计出近似w的解： $w_k = - \frac{L_k^&lsquo;(0)}{L_k^&ldquo;(0)}$<br/>
其中，
$$
L_k^{&rsquo;}(0) = \sum_i p_i - \frac{y_i + 1}{2}
$$
$$
L_k^{&lsquo;&rsquo;}(0) = \sum_i p_i (1 - p_i)
$$
$$
p_i = \frac{1}{1 + exp(-s_i)}
$$</p>

<p>一旦w计算完成，我们可以估计出加入w特征后logLoss的改进值，
$$
\Delta logLoss = \sum_k w_k L_k^{&lsquo;}(0) + 0.5 w_{k}^2 L_k^{&rsquo;&lsquo;}(0)
$$
这个改进值可以视为新特征相对已有特征集合下对学习任务的条件互信息。</p>

<p>因此特征选择的过程可以归纳为如下算法： <br/>
（1）选择从一个基本特征集合开始<br/>
（2）对已有特征训练一个模型<br/>
（3）对待选择的特征逐一计算条件互信息( $\Delta logLoss$ ）<br/>
（4）选择 $\Delta logLoss$ 最小的，把对应特征加入已有特征集合<br/>
（5）重复（2）步</p>

<ul>
<li><p><strong>一些可以讨论的问题</strong></p>

<p><em>反馈特征</em><br/>
一些业界公司（如m6d，weibo）会实时统计如广告主、广告计划等各个维度的点击率，以及上下文和广告直接交叉维度的点击率，这些实时反馈的特征作为模型训练的特征。对于使用这类特征业界实际是有争议的：一种考虑是反馈特征统计口径界定容易造成生成的条件概率意义相对模糊，形成的连续数值特征离散化处理对最终效果影响较大，尤其是取值范围高位和地位孤立点很多，不易做好离散化。<br/>
反馈特征的一个特点是一旦广告或推荐系统平稳后，反馈取值范围也是稳定的，这样可以一次性完成ETL和模型训练过程，之后模型的权重很长时间都不会变化，即使变化也可以通过较小的代价以原模型权重为初值训练完成。这种方式很适合训练过程非常耗时，不能频繁更新模型的情况。</p>

<p><em>CTR .vs. CVR</em><br/>
转化率预估是比点击率预估正样本量更小的学习任务，因此样本倾斜、数据稀疏等问题都更加严重了。因此，常常吧转化率预估问题转化为点击率预估和点击后的转化率预估（pCVR预估），以减轻一些数据问题带来的严重性。
此外，转化率对特征的考虑也是不一样的，诸如上下文环境等和媒体相关的特征对最终的转化价值都大大降低，但用户基本属性与广告或商品属性的相关性特征对转化率起到大大的作用，这是需要仔细挖掘和分析的。</p>

<p><em>模型后处理</em><br/>
这里涉及的主要是missing feature的问题，当新样本的特征不在学习好的模型特征集合中时，逻辑函数计算 $\sum wx$ 的线性加和中某些项就查不到权重，这样估计值就会出现极大的偏差。解决这种主要是对原有特征按照类别和联合层次建立一个针对missing feature的查找体系，从而解决线上新特征的权重赋值问题。</p></li>
</ul>


<p>最后，本博客涉及的特征处理、采样、模型后处理等策略涉及的具体实现，可以参考本人的github项目：<a href="https://github.com/xuyuandong/mapreduce_etl/tree/master">https://github.com/xuyuandong/mapreduce_etl/tree/master</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/">http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/05/post-title/">从GitHub启程</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-07-05T14:51:57+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>5</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>2:51 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><hr />

<p>步入互联网行业早已超过三年，直到现在才开始建立自己的博客。在学校读书的时候虽然也有过几次写技术博客的日子，但都没有坚持下来，一是因为自己懒于把总结和整理的东西再编辑好发表出来，二是写着写着确实觉得才疏学浅，干货太少。工作之后，进度很快，也更忙碌了，一回首发现几年前接触的东西竟然快忘掉，电脑里只剩下一个个很难再去翻看的文件夹，于是发现，是时候该总结了。</p>

<p>回顾自己工作这几年，做过搜索、推荐、广告的系统架构和数据挖掘，但主要是在搜索、广告的一些关键技术和策略点上进行过深入的思考和开发，总结了一些面上的slides和点上code，这将在github这个平台上一一分享。特别感谢@Easy 让我有动力在github上开博客，而我电脑里这些沉积的资料也大部分是从工作过程中认识的内部的外部的同事朋友以及网络上感觉比较靠谱的分享中学习总结出来的，互联网的开放精神让这个行业飞快的进步，也让每个程序员都因此受益。</p>

<p>本篇我先粗描淡写讲一下如何用github打造个人blog，主要是援引网络上几个博客的内容。</p>

<ol>
<li><p>用github建立blog的原理  </br>
不错，用github写博客就像前端开发，这要从完整的博客系统角度理解。
博客系统需要一个类似CMS的博客站点管理部分，和一个后台的数据库，展示博客时系统会从数据库中获得内容动态形成HTML页面进行前端展示；然而，github和网上类似新浪博客的系统的区别是，他没有一个为博客定制的页面形成系统和数据库，但他是具有版本管理功能的代码仓库，所以我们只能通过把动态形成的页面变成静态页面，然后像代码一样提交给github，浏览博客是通过访问组织好的静态页面完成的。</p></li>
<li><p>配置ruby开发环境  </br>
<em>关键词：brew, ruby, rvm, rbenv, bundler</em><br/>
我个人不懂前端开发，所以也不太了解上面这些东西是什么，基本上就是照着网上一些文章照搬的，中间会发生不少错误，提示缺什么就装什么，基本能够搞定，我完成后看了一下自己的bash history，大致按照这么几条比较重要的命令：<br/>
[安装rvm]<br/>
<code>curl -sSL https://get.rvm.io | bash -s stable</code><br/>
[安装ruby]<br/>
<code>rvm install ruby-2.0.0-p594 &amp;&amp; rvm use 2.0.0</code><br/>
[安装brew]<br/>
<code>ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</code><br/>
<code>brew tab --repair</code><br/>
<code>brew update</code><br/>
[安装rbenv]<br/>
<code>brew install rbenv</code><br/>
<code>rbenv rehash</code><br/>
[按照bundler]<br/>
<code>gem update --system</code><br/>
<code>gem install bundler</code><br/>
<code>bundle install</code><br/>
到这里基本上装完了，不同系统由于曾经有过安装或者版本问题导致安装的过程都不会完全顺利，装成与否就看下一步octopress配置是否成功</p></li>
<li><p>配置和使用octopress  </br>
octopress是一个开发HTML静态页面网站的系统，在这个系统内我们只需要编辑MarkDown文件的内容就好了，页面风格主题之类的都交给octopress配置一下执行几个命令就能生成HTML静态页面网站，包括那些css，js文件等等，octopress可以和github关联起来，把静态页面网站提交给github，我们就可以通过github访问建好的博客站点了。<br/>
[注册个人github账号]<br/>
这一步就上github网站安装提示一步步来吧<br/>
[创建github上的blog项目]<br/>
按照这个链接来，有截图<a href="http://blog.csdn.net/renfufei/article/details/37725057  ">http://blog.csdn.net/renfufei/article/details/37725057  </a>
你会获得一个blog访问地址，比如：xxx.github.io/blog/<br/>
[下载并配置octopress]<br/>
<code>git clone git://github.com/imathis/octopress.git ~/dev/octopress</code> <br/>
<code>cd ~/dev/octopress</code>  <br/>
<code>rake install</code><br/>
<code>git remote add blog git@xxx.git</code> <br/>
[写第一篇blog]<br/>
<code>rake new_post["my first blog title"]</code><br/>
然后到~/dev/octopress/source/_posts/下找到对应的markdown文件编辑这篇博客<br/>
[生成静态网站]<br/>
<code>rake generate</code><br/>
[关联对应的git项目]<br/>
<code>rake setup_github_pages</code><br/>
[在4000端口预览]<br/>
<code>rake preview</code><br/>
[发布到github上]<br/>
<code>rake deploy</code></p></li>
</ol>


<p>到此大功告成，不过后面不断发布博客的过程中，还会遇到很多问题，比如git的版本管理问题，blog的格式问题，越多的问题就越要了解一些各方面的知识，比如git的使用，markdown语法，octopress的原理等等。</p>

<p>最后，希望本博客能够坚持写下去，发布更多搜索、推荐、广告、和数据挖掘相关内容！！！</p>

<p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/'>http://xuyuandong.github.io/blog/blog/2014/07/05/post-title/</a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'>http://xuyuandong.github.io/blog</a>
            </p>

</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/index.html">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/blog/2014/12/03/dmp-tutorial/">广告数据管理平台漫谈</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/11/10/scalable-web-systems/">可扩展网站架构与分布式系统</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/11/06/matrix-factorization/">矩阵分解在广告、推荐技术中的应用</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/11/02/architecture/">程序化购买下的广告技术架构</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/10/19/allocation/">流量分配与规划算法</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - XuYuandong -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
