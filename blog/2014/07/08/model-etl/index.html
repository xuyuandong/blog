
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>基于模型的CTR预估与ETL - Mr X&#8217;s blog</title>
  <meta name="author" content="XuYuandong">

  
  <meta name="description" content="在广告和推荐业务中，让人感觉最核心和高大上的一块就是CTR（点击率）预估。基于机器学习模型的CTR预估，说白了就是利用已有的投放数据（包括曝光和点击日志）学习出一组参数表示的函数，输入我们认为对CTR有影响的因素（特征），函数给出我们一个估计出的CTR结果，因此， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl">
  <link href="/blog/favicon.png" rel="icon">
  <link href="/blog/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/blog/atom.xml" rel="alternate" title="Mr X's blog" type="application/atom+xml">
  <script src="/blog/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/blog/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/blog/">Mr X&#8217;s blog</a></h1>
  
    <h2>Taste the life and figure out the meaning</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/blog/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:xuyuandong.github.io/blog" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/blog/">Blog</a></li>
  <li><a href="/blog/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">基于模型的CTR预估与ETL</h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2014-07-08T12:21:44+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>12:21 pm</span></time>
        
      </p>
    
  </header>


<div class="entry-content"><hr />

<p>在广告和推荐业务中，让人感觉最核心和高大上的一块就是CTR（点击率）预估。基于机器学习模型的CTR预估，说白了就是利用已有的投放数据（包括曝光和点击日志）学习出一组参数表示的函数，输入我们认为对CTR有影响的因素（特征），函数给出我们一个估计出的CTR结果，因此，基于模型的CTR预估主要工作时对特征的研究和对模型的研究。</p>

<p>由于广告、搜索的业务每家公司都不太一样，涉及到的场景会有所区别，因此对问题的建模也会有所不同，这不但衍生出了机器学习模型本身的变化（我们将再另一篇里专门讨论），更多的不同都体现在了对业务数据的处理，即是对特征的处理，尽可能把问题在特征层面规约到几个标准化的机器学习问题上。这篇文章将以CTR预估最常用的LR模型为例，主要讨论在大数据情况下具体实战时，该怎么建立整个数据处理、模型训练和效果预估流程，这些更多是ETL层面的问题。</p>

<ul>
<li><strong>LR模型</strong></li>
</ul>


<p>有人问我为什么CTR预估最常用LR模型，我想先思考一下这个问题的特点：<br/>
1. 训练标签是离散的0或1<br/>
2. 输出要求是[0~1]之间的概率<br/>
3. 其他原因，如线性模型学习效率上的优点等</p>

<p>对于点击或不点击这种事情，天然满足二项分布的似然损失函数：<br/>
$$
-log(F) = -\frac{1}{n} \sum_{i=1}^n \left[y_i \log(p_i) + (1 - y_i)\log(1 - p_i)\right]
$$</p>

<p>其中二项分布中的预测概率是逻辑函数<br/>
$$
Pr(y=1|x,w) = \frac{1}{1 + exp(-w^{T}x)}<br/>
$$
时，这就是逻辑回归（LR）模型了。通常为了防止过拟合，会在损失函数上加入正则项，L2正则项相当于给二项分布似然函数加上了高斯分布的先验，L1正则项相当于加入拉普拉斯先验。此外，需要指出的是逻辑回归中使用的特征一般要求是二值类别特征，即0/1特征。</p>

<ul>
<li><strong>准备数据</strong></li>
</ul>


<p>对于CTR预估来讲，根据数据动态变化情况不同，需要准备短至7天，长达1年的训练数据；数据是按天分区的，首先要分析一下数据中每日新增的广告或商品的比例，以及数据中新增率、天然点击率的周期性，这些对于选择时间窗口是非常有意义的。</p>

<p>假如我们有8天的训练数据，选择时间窗口为7天，我们则按照时间先后顺序，将数据划分为训练集（前7天），测试集（后1天），对于机器学习领域提到的验证集（主要是用来调超参数用的），可以用训练集数据再划分做交叉验证的方法，或者直接划出部分测试集。</p>

<p>在实战中，一旦建立起模型并应用于线上，验证集一般就不需要了，除非模型除了大偏差需要重调，否则既浪费时间模型又不稳定。测试集一般也是不存在的，因为上线时总是希望用全部最新的数据去训练。Google提出过一种progressive validation的方法，使用Online Learning时可以边训练边测试评估，评估结果能够在一定程度上表征模型的好坏，我们再另一篇专门讨论模型的文章中会再提到。</p>

<p>由于上线后模型每天都要跑，所以数据的收集和整理一定要是增量式的，流程上采用一个滚动时间窗口的机制，可以减少处理数据的时间，加速模型的更新速度，提高效果。如果广告或商品的新增速度过快，每日更新模型都不足以保证效果的实时性，就需要小时级更新的模型或者实时模型；对于小时级模型，建议与每日模型分别批量训练并在使用策略上做模型混合；对于实时模型，整个ETL流程都是在线增量计算的，工程实现上会有较大区别，但思想上是一致，所以本文主要是谈批量的ETL处理流程。</p>

<ul>
<li><strong>数据格式</strong></li>
</ul>


<p>一般大公司都会用Hadoop家族的开源工具来管理自己的数据仓库，因此建议使用hive来管理自己的曝光、点击日志，生成的训练数据格式可以包括：0/1标签信息，曝光环境，广告信息，用户信息等四类信息。其中，<br/>
曝光环境包括：流量来源、网络环境、页面上下文属性等；<br/>
广告信息包括：广告和创意、广告计划、广告主的ID和相关属性，越具体越好；<br/>
用户信息包括：人口属性、短期长期兴趣标签、和当前广告的互动频次等，越具体越好；</p>

<ul>
<li><strong>特征处理</strong></li>
</ul>


<p>首先，需要明确偏置特征因子，怎么明确呢？想象一下我们的CTR预估使用场景，当某个广告位上某个用户访问时，需要从一组广告中选择一个CTR最高的投放出去，在这个场景下，曝光上下文环境和用户都是确定的，只有广告可以变化，所以上下文和用户特征就是偏置因子，它们对候选集合来说是不变的，只决定CTR的整体大小水平，不决定相对区分力。</p>

<p>单独把偏置因素纳入到训练数据的特征集合是没有意义的，因为在使用时它们不能起到区别作用。解决这个问题有2种方法，一种是在模型建模时就把偏置因素考虑进去，这将形成对LR模型的一个变种；另一种办法是把偏置因素和广告进行交叉组合，形成联合特征，每个联合的特征才能表示当前广告在特征偏置条件下的一个特征；考虑上下文-用户-广告的三联合甚至更多维的联合，将导致特征数量迅速膨胀，但每种特征都是很细化的一种情况，统计不一定充分，整体日志量相比特征集合大小也得不充分了，每条样本包含的特征数量占据整体特征集合非常小的一部分，这就形成了CTR预估的高维稀疏的数据问题，因而给机器学习领域造成了一定的挑战。</p>

<p>做特征处理时，我一般会先对样本的交叉特征出现的正负样本数进行统计，每一类交叉特征中识别出有容易造成过拟合的问题特征，进行过滤掉部分问题样本。对于不充分统计的特征，可以考虑进行按特征联合的层次进行聚类，不充分的特征归约到一起，如果整层都不充分就归约到上一层，这样不但可以降低特征维度，也可以防止这类特征权重学习不充分导致的过拟合。此外，对于连续数值形特征，需要做离散区间化处理，归为2值特征，这样一能减少特征维度，二能更好描述非线性状态空间。关于特征变换和离散化是一个可以进一步挖掘的问题，我将在另外一篇博客中单独来讨论。</p>

<p>下面我们考虑用MapReduce实现这个过程：可以考虑在Map阶段完成从原始训练数据按照配置文件进行联合交叉特征的生成，然后发送给Reduce阶段；可以设置Partition方法按照特征类别进行分区，在Reduce阶段设置Grouping方法把需要层次聚类的一组特征划到同一个reduce阶段，进而完成特征的聚类、特征变换和离散化处理等过程。</p>

<ul>
<li><strong>多任务学习</strong></li>
</ul>


<p>实际业务中，广告和商品投放在不同的流量来源位置是很常见的，不同位置带来的流量可能有2种情况：一是人群分布相同或相似，二是人群分布差异很大；</p>

<p>对于第一种情况，流量对应的人群差异不大，位置主要影响了曝光的可见性，造成点击率整体上有偏置差异，但对CTR的相对分布影响不大。这种问题建议修改建模方式，如采用transfer learning，position normalization之类的策略，能够利用上全部训练数据做模型学习，取得的效果会更好。这部分我将在专门讨论模型的文章中说明。</p>

<p>对于第二种情况，就需要分别做处理，比如分位置做训练，把每个位置的CTR预估看成一个独立的问题解决。其实，也可以一起训练，但是要求所有特征都要和位置ID做联合，这样可以在优化时起到隔离作用；这样可以在一次优化过程中完成多任务学习。</p>

<p><em>结合VW的训练过程</em></p>

<p>VW是Vowpal Wabbit缩写，是工业界常用的一个开源机器学习工具，支持在Hadoop上对大规模数据使用AllReduce方式分布式训练机器学习模型。使用VW需要将训练样本转换成其要求的格式，更多的详情可以参考：<a href="https://github.com/JohnLangford/vowpal_wabbit/wiki">https://github.com/JohnLangford/vowpal_wabbit/wiki</a></p>

<p>首先，我们需要把特征进行编号（特征ID化），目的是在优化损失函数时，各个维度互不冲突。使用MapReduce的处理方式，可以对上一小节的联合特征处理结果在Map阶段按照资源位置进行分发，在Reduce阶段顺序编号。这样可以保证同一个资源位（同一个学习任务）内的特征ID互不冲突，使用资源位ID作为特征名字空间，能够保证即使所有位置一起优化，也不会彼此干扰。</p>

<p>然后，我们使用ID化之后的特征对原始训练数据进行编码，生成VW需要的格式;因为特征文件也是很大规模的数据，因此需要用MapReduce的多路输入方式，按资源位进行分发，在Reduce阶段进行特征ID与样本数据的关联和格式转换，形成可用的样本。</p>

<p>最后，直接使用VW提供的脚本即可完成模型的学习。</p>

<ul>
<li><strong>样本倾斜</strong></li>
</ul>


<p>众所周知，广告或推荐的点击数据相比曝光数量是非常小的，这样我们的训练样本中正样本的比例也是非常小的（常常 &lt; 1%），这种情况被成为样本倾斜。一些机器学习算法是对正负样本比例敏感的，好在我们使用的逻辑回归模型并不如此。不过从以下几个角度考虑，我们还是要讨论一下负样本采样的重要性：<br/>
1. 降低训练数据的规模，加速模型学习过程<br/>
2. 负样本中抽样能够使训练过程泛化能力更强，有助于减少测试集上的误差<br/>
对于第二点，我认为主要是解决了非常不充分的噪声特征，减少了模型过拟合的可能性，但是绝大部分情况下良好的模型选择和数据清洗过程才是保证泛化能力的关键，因此加速模型学习效率是考虑样本下采样的关键因素。</p>

<p>对负样本的下采样其实是模型训练效率与准确率之间的一种trade off，原理上其实是不会改变预估结果的，负样本抽样的原理如下：<br/>
$$
\frac{P(y=1|x)}{P(y=-1|x)} = \frac{P(x|y=1)P(y=1)}{P(x|y=-1)P(y=-1)} = \frac{P&#8217;(x|y=1)P&#8217;(y=1)}{P&#8217;(x|y=-1)P(y=-1)/r} = r \frac{P&#8217;(y=1|x)}{P&#8217;(y=-1|x)}
$$<br/>
上面等式成立的前提是负样本采样不改变类别的条件概率分布：$P(x|y)=P&#8217;(x|y)$ 。这样，进行采样后，我们的负对数损失函数会被降低 $log r$ ，有2种办法解决这个问题：<br/>
1. 训练完成模型后，在预测时将模型权重线性加和后，在加上 $log r$ 做补偿；
2. 训练过程中，对采样后保留下来的负样本提升 $1/r$ 权重，从而保证损失函数不变；<br/>
实践中，第一种处理方法的泛化能力比较好，方法二得到的模型在测试集上并不理想，可能的解释是对样本进行重要性加权的做法会破坏了原本的泛化错误边界。</p>

<ul>
<li><strong>评价指标</strong></li>
</ul>


<p>评价点击率预估效果有几种方式可以参考：<br/>
1. <em>auROC</em> 最常见的评价方式，能够解释是否点击率预估的越高，覆盖的真实点击数比例越大；auROC除了常见的计算曲线覆盖面积方式外，还有一种有意思的计算方法：随机从样本集中取一个正样本和一个负样本，统计正样本预估CTR比负样本预估CTR高的概率，这也一定程度上解释了它的物理意义。 <br/>
auROC的问题是换一个数据集，当正负样本比例变了，评价值就没有可比性了；因此指标只能用于静态数据集上不同方法的实验对比。值得注意的是，单纯谈论auROC的大小是没有意义的，不一样的数据集，一个AUC=0.9，一个AUC=0.7，不能说明前者算法就比后者好。<br/>
2. <em>logLoss</em> 直接带入损失函数计算结果，因为二项分布是对称的，所以评价值对正负样本比例不敏感，对损失函数按样本数量做平均后，可以用于横向对比。不过，我觉得预测值的方差范围是会对评估结果有影响的，但是预测值方差范围也是算法的一个评价方面，因此不能说这是该评价指标的缺点。<br/>
以上两种都是比较核心的评价指标，此外，还有一些辅助性的效果监控方法，用于探测模型其他方面的问题：<br/>
3. <em>calibration</em> 我们把样本按预估点击率排序，在数轴上对预估点击率划分等长区间，每个区间内落入的样本数可以统计正样本比例（即该区间内真是点击率），这两个点击率分别绘制在二维左边系横轴和纵轴上，理论上应该是满足y=x的一条直线。实际上，围绕着y=x的波动范围体现出预估的方差，偏离程度预示着偏差，还可以看出模型在点击率高位预估的好还是低位预估的好，这往往预示着模型对如missing feature等因素处理的效果等问题。<br/>
此外，对每类特征都进行calibration监测是一个好方法，能够更细致的发现模型内部的问题。</p>

<ul>
<li><strong>特征选择</strong></li>
</ul>


<p>提到特征选择，一般有2种理解：一是特征类别的选择，二是特征取值的选择。学术界有一部分研究专门通过模型优化来进行特征选择，如L1正则化来进行特征取值的选择，L1/L2 group lasso方法同时进行特征类别和取值的选择；不过这类把所有问题都交给优化算法，一是会导致人工控制的不够，二是计算复杂性也是大大增加了，此外能够处理大规模数据的开源项目和工具还不成熟。其实，工业界中花人力最多的特征工程还是通过实验方法挖掘哪些类特征该加入模型，以及如何融入到已存在的一大堆特征类别中，达到最优的组合。</p>

<p>假如我们有N种特征，直观的方法是做O(2<sup>N</sup>)种选择构造候选特征集合，然后训练这么多个模型，选择效果最好的，代价是时间成本。如果要把指数实验次数降下来，可以考虑用动态规划的方法把实验次数降至O(N<sup>2</sup>)，我们这里介绍用贪心策略将实验次数降至O(N).</p>

<p>让人耳熟能详的特征选择方法，如互信息等，能够评价特征与分类任务的相关性，但是没有考虑到如果已经存在了一批特征之后，如何再往特征集合里添加新特征。我们现在将问题建模如下，假设存在一批特征构成的LR模型，其logLoss为：<br/>
$$
\sum_{i=1}^n log(1 + exp(-y_i s_i))
$$</p>

<p>对于要加入的特征 $W = [w_1, &hellip;, w_d]$ ，第i个样本的预测值则为 $s_i + w_i$ ，需要优化的损失函数为：
$$
logLoss = \sum_{i=1}^n log(1 + exp(-y_i (s_i + w_i)))
$$</p>

<p>进一步分解为（各 $w_k$ 独立优化）：
$$
logLoss = \sum_k \sum_i log(1 + exp(-y_i (s_i + w_k)))
$$
这样问题转化为确定s条件下优化w以使logLoss最小的问题。</p>

<p>可以跟进一次牛顿迭代估计出近似w的解： $w_k = - \frac{L_k^&lsquo;(0)}{L_k^&ldquo;(0)}$<br/>
其中，
$$
L_k^{&rsquo;}(0) = \sum_i p_i - \frac{y_i + 1}{2}
$$
$$
L_k^{&lsquo;&rsquo;}(0) = \sum_i p_i (1 - p_i)
$$
$$
p_i = \frac{1}{1 + exp(-s_i)}
$$</p>

<p>一旦w计算完成，我们可以估计出加入w特征后logLoss的改进值，
$$
\Delta logLoss = \sum_k w_k L_k^{&lsquo;}(0) + 0.5 w_{k}^2 L_k^{&rsquo;&lsquo;}(0)
$$
这个改进值可以视为新特征相对已有特征集合下对学习任务的条件互信息。</p>

<p>因此特征选择的过程可以归纳为如下算法： <br/>
（1）选择从一个基本特征集合开始<br/>
（2）对已有特征训练一个模型<br/>
（3）对待选择的特征逐一计算条件互信息( $\Delta logLoss$ ）<br/>
（4）选择 $\Delta logLoss$ 最小的，把对应特征加入已有特征集合<br/>
（5）重复（2）步</p>

<ul>
<li><p><strong>一些可以讨论的问题</strong></p>

<p><em>反馈特征</em><br/>
一些业界公司（如m6d，weibo）会实时统计如广告主、广告计划等各个维度的点击率，以及上下文和广告直接交叉维度的点击率，这些实时反馈的特征作为模型训练的特征。对于使用这类特征业界实际是有争议的：一种考虑是反馈特征统计口径界定容易造成生成的条件概率意义相对模糊，形成的连续数值特征离散化处理对最终效果影响较大，尤其是取值范围高位和地位孤立点很多，不易做好离散化。<br/>
反馈特征的一个特点是一旦广告或推荐系统平稳后，反馈取值范围也是稳定的，这样可以一次性完成ETL和模型训练过程，之后模型的权重很长时间都不会变化，即使变化也可以通过较小的代价以原模型权重为初值训练完成。这种方式很适合训练过程非常耗时，不能频繁更新模型的情况。</p>

<p><em>CTR .vs. CVR</em><br/>
转化率预估是比点击率预估正样本量更小的学习任务，因此样本倾斜、数据稀疏等问题都更加严重了。因此，常常吧转化率预估问题转化为点击率预估和点击后的转化率预估（pCVR预估），以减轻一些数据问题带来的严重性。
此外，转化率对特征的考虑也是不一样的，诸如上下文环境等和媒体相关的特征对最终的转化价值都大大降低，但用户基本属性与广告或商品属性的相关性特征对转化率起到大大的作用，这是需要仔细挖掘和分析的。</p>

<p><em>模型后处理</em><br/>
这里涉及的主要是missing feature的问题，当新样本的特征不在学习好的模型特征集合中时，逻辑函数计算 $\sum wx$ 的线性加和中某些项就查不到权重，这样估计值就会出现极大的偏差。解决这种主要是对原有特征按照类别和联合层次建立一个针对missing feature的查找体系，从而解决线上新特征的权重赋值问题。</p></li>
</ul>


<p>最后，本博客涉及的特征处理、采样、模型后处理等策略涉及的具体实现，可以参考本人的github项目：<a href="https://github.com/xuyuandong/mapreduce_etl/tree/master">https://github.com/xuyuandong/mapreduce_etl/tree/master</a><p class='post-footer'>
            原文地址
            <a href='http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/'><a href="http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/">http://xuyuandong.github.io/blog/blog/2014/07/08/model-etl/</a></a><br/>
            &nbsp;written by <a href='http://xuyuandong.github.io/blog'>XuYuandong</a>
            &nbsp;posted at <a href='http://xuyuandong.github.io/blog'><a href="http://xuyuandong.github.io/blog">http://xuyuandong.github.io/blog</a></a>
            </p></p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">XuYuandong</span></span>

      




<time class='entry-date' datetime='2014-07-08T12:21:44+08:00'><span class='date'><span class='date-month'>Jul</span> <span class='date-day'>8</span><span class='date-suffix'>th</span>, <span class='date-year'>2014</span></span> <span class='time'>12:21 pm</span></time>
      


    </p>
    
      <div class="sharing">
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/blog/2014/07/05/post-title/" title="Previous Post: 从GitHub启程">&laquo; 从GitHub启程</a>
      
      
        <a class="basic-alignment right" href="/blog/blog/2014/07/16/prediction-model/" title="Next Post: 点击率预估的机器学习模型及具体应用中的变种">点击率预估的机器学习模型及具体应用中的变种 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/blog/2014/11/06/matrix-factorization/">矩阵分解在广告、推荐技术中的应用</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/11/02/architecture/">程序化购买下的广告技术架构</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/10/19/allocation/">流量分配与规划算法</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/10/07/budget-smooth/">预算平滑与在线分配策略</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2014/09/26/user-profile/">利用社交网络与行为定向建立用户模型</a>
      </li>
    
  </ul>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2014 - XuYuandong -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
